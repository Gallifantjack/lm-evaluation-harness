{
  "results": {
    "medmcqa_g2b": {
      "acc,none": 0.49712643678160917,
      "acc_stderr,none": 0.026840963072481176,
      "acc_norm,none": 0.49712643678160917,
      "acc_norm_stderr,none": 0.026840963072481176,
      "alias": "medmcqa_g2b"
    },
    "medmcqa_g2b_hint": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.026841406354750946,
      "acc_norm,none": 0.5,
      "acc_norm_stderr,none": 0.026841406354750946,
      "alias": "medmcqa_g2b_hint"
    },
    "medmcqa_orig_filtered": {
      "acc,none": 0.5948275862068966,
      "acc_stderr,none": 0.026354255237958743,
      "acc_norm,none": 0.5948275862068966,
      "acc_norm_stderr,none": 0.026354255237958743,
      "alias": "medmcqa_orig_filtered"
    },
    "medqa_4options_g2b": {
      "acc,none": 0.5529100529100529,
      "acc_stderr,none": 0.02560672399577702,
      "acc_norm,none": 0.5529100529100529,
      "acc_norm_stderr,none": 0.02560672399577702,
      "alias": "medqa_4options_g2b"
    },
    "medqa_4options_g2b_hint": {
      "acc,none": 0.5608465608465608,
      "acc_stderr,none": 0.025559920550531003,
      "acc_norm,none": 0.5608465608465608,
      "acc_norm_stderr,none": 0.025559920550531003,
      "alias": "medqa_4options_g2b_hint"
    },
    "medqa_4options_orig_filtered": {
      "acc,none": 0.5952380952380952,
      "acc_stderr,none": 0.025279850397404907,
      "acc_norm,none": 0.5952380952380952,
      "acc_norm_stderr,none": 0.025279850397404907,
      "alias": "medqa_4options_orig_filtered"
    }
  },
  "configs": {
    "medmcqa_g2b": {
      "task": "medmcqa_g2b",
      "dataset_path": "AIM-Harvard/medmcqa_generic_to_brand",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x70fdb9129940>",
      "doc_to_target": "cop",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "{{question}}"
    },
    "medmcqa_g2b_hint": {
      "task": "medmcqa_g2b_hint",
      "dataset_path": "AIM-Harvard/medmcqa_generic_to_brand",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x70fdb94a0dc0>",
      "doc_to_target": "cop",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "{{question}}"
    },
    "medmcqa_orig_filtered": {
      "task": "medmcqa_orig_filtered",
      "dataset_path": "AIM-Harvard/medmcqa_original",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x70fdb94a0b80>",
      "doc_to_target": "cop",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "{{question}}"
    },
    "medqa_4options_g2b": {
      "task": "medqa_4options_g2b",
      "dataset_path": "AIM-Harvard/gbaker_medqa_usmle_4_options_hf_generic_to_brand",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "<function doc_to_text at 0x70fdb9413940>",
      "doc_to_target": "<function doc_to_target at 0x70fdb9413ca0>",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false
    },
    "medqa_4options_g2b_hint": {
      "task": "medqa_4options_g2b_hint",
      "dataset_path": "AIM-Harvard/gbaker_medqa_usmle_4_options_hf_generic_to_brand",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "<function doc_to_text at 0x70fdb9593dc0>",
      "doc_to_target": "<function doc_to_target at 0x70fdb95381f0>",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false
    },
    "medqa_4options_orig_filtered": {
      "task": "medqa_4options_orig_filtered",
      "dataset_path": "AIM-Harvard/gbaker_medqa_usmle_4_options_hf_original",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "<function doc_to_text at 0x70fdb9413d30>",
      "doc_to_target": "<function doc_to_target at 0x70fdb941b040>",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false
    }
  },
  "versions": {
    "medmcqa_g2b": "Yaml",
    "medmcqa_g2b_hint": "Yaml",
    "medmcqa_orig_filtered": "Yaml",
    "medqa_4options_g2b": "Yaml",
    "medqa_4options_g2b_hint": "Yaml",
    "medqa_4options_orig_filtered": "Yaml"
  },
  "n-shot": {
    "medmcqa_g2b": 0,
    "medmcqa_g2b_hint": 0,
    "medmcqa_orig_filtered": 0,
    "medqa_4options_g2b": 0,
    "medqa_4options_g2b_hint": 0,
    "medqa_4options_orig_filtered": 0
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=meta-llama/Meta-Llama-3.1-8B",
    "batch_size": "auto",
    "batch_sizes": [
      8
    ],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": null
  },
  "git_hash": "04969124"
}