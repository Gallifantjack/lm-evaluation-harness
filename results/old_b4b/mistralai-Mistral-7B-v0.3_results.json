{
  "results": {
    "b4b": {
      "acc,none": 0.5824659727782225,
      "acc_stderr,none": 0.08515424221657852,
      "acc_norm,none": 0.581814415907208,
      "acc_norm_stderr,none": 0.007339897717417354,
      "alias": "b4b"
    },
    "b4bqa": {
      "acc,none": 0.703125,
      "acc_stderr,none": 0.010795811437682205,
      "acc_norm,none": 0.703125,
      "acc_norm_stderr,none": 0.010795811437682205,
      "alias": " - b4bqa"
    },
    "medmcqa_b2g": {
      "acc,none": 0.5634920634920635,
      "acc_stderr,none": 0.022113423407025164,
      "acc_norm,none": 0.5634920634920635,
      "acc_norm_stderr,none": 0.022113423407025164,
      "alias": " - medmcqa_b2g"
    },
    "medmcqa_g2b": {
      "acc,none": 0.45436507936507936,
      "acc_stderr,none": 0.022200847780753347,
      "acc_norm,none": 0.45436507936507936,
      "acc_norm_stderr,none": 0.022200847780753347,
      "alias": " - medmcqa_g2b"
    },
    "medmcqa_orig_filtered": {
      "acc,none": 0.5654761904761905,
      "acc_stderr,none": 0.022101917752795727,
      "acc_norm,none": 0.5654761904761905,
      "acc_norm_stderr,none": 0.022101917752795727,
      "alias": " - medmcqa_orig_filtered"
    },
    "medqa_4options_b2g": {
      "acc,none": 0.5118110236220472,
      "acc_stderr,none": 0.022199583294816916,
      "acc_norm,none": 0.5118110236220472,
      "acc_norm_stderr,none": 0.022199583294816916,
      "alias": " - medqa_4options_b2g"
    },
    "medqa_4options_g2b": {
      "acc,none": 0.4566929133858268,
      "acc_stderr,none": 0.022122328731374537,
      "acc_norm,none": 0.4566929133858268,
      "acc_norm_stderr,none": 0.022122328731374537,
      "alias": " - medqa_4options_g2b"
    },
    "medqa_4options_orig_filtered": {
      "acc,none": 0.5098425196850394,
      "acc_stderr,none": 0.02220147678894261,
      "acc_norm,none": 0.5098425196850394,
      "acc_norm_stderr,none": 0.02220147678894261,
      "alias": " - medqa_4options_orig_filtered"
    },
    "mmlu_professional_medicine_b2g": {
      "acc,none": 0.6071428571428571,
      "acc_stderr,none": 0.0658538889806635,
      "alias": " - mmlu_professional_medicine_b2g"
    },
    "mmlu_professional_medicine_g2b": {
      "acc,none": 0.5892857142857143,
      "acc_stderr,none": 0.06633634150359542,
      "alias": " - mmlu_professional_medicine_g2b"
    },
    "mmlu_professional_medicine_orig_filtered": {
      "acc,none": 0.6071428571428571,
      "acc_stderr,none": 0.0658538889806635,
      "alias": " - mmlu_professional_medicine_orig_filtered"
    }
  },
  "groups": {
    "b4b": {
      "acc,none": 0.5824659727782225,
      "acc_stderr,none": 0.08515424221657852,
      "acc_norm,none": 0.581814415907208,
      "acc_norm_stderr,none": 0.007339897717417354,
      "alias": "b4b"
    }
  },
  "configs": {
    "b4bqa": {
      "task": "b4bqa",
      "dataset_path": "AIM-Harvard/b4b_drug_qa",
      "test_split": "test",
      "doc_to_text": "<function process_cd at 0x7f446da5ff70>",
      "doc_to_target": "correct_choice",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false
    },
    "medmcqa_b2g": {
      "task": "medmcqa_b2g",
      "dataset_path": "AIM-Harvard/medmcqa_brand_to_generic",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x7f446da82af0>",
      "doc_to_target": "cop",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "{{question}}"
    },
    "medmcqa_g2b": {
      "task": "medmcqa_g2b",
      "dataset_path": "AIM-Harvard/medmcqa_generic_to_brand",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x7f446df9b430>",
      "doc_to_target": "cop",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "{{question}}"
    },
    "medmcqa_orig_filtered": {
      "task": "medmcqa_orig_filtered",
      "dataset_path": "AIM-Harvard/medmcqa_original",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x7f446d8c63a0>",
      "doc_to_target": "cop",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "{{question}}"
    },
    "medqa_4options_b2g": {
      "task": "medqa_4options_b2g",
      "dataset_path": "AIM-Harvard/gbaker_medqa_usmle_4_options_hf_brand_to_generic",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "<function doc_to_text at 0x7f446d8c65e0>",
      "doc_to_target": "<function doc_to_target at 0x7f446d8c6940>",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false
    },
    "medqa_4options_g2b": {
      "task": "medqa_4options_g2b",
      "dataset_path": "AIM-Harvard/gbaker_medqa_usmle_4_options_hf_generic_to_brand",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "<function doc_to_text at 0x7f446df9b8b0>",
      "doc_to_target": "<function doc_to_target at 0x7f446df9bc10>",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false
    },
    "medqa_4options_orig_filtered": {
      "task": "medqa_4options_orig_filtered",
      "dataset_path": "AIM-Harvard/gbaker_medqa_usmle_4_options_hf_original",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "<function doc_to_text at 0x7f446da82550>",
      "doc_to_target": "<function doc_to_target at 0x7f446da2ff70>",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false
    },
    "mmlu_professional_medicine_b2g": {
      "task": "mmlu_professional_medicine_b2g",
      "dataset_path": "AIM-Harvard/hails_mmlu_no_train_professional_medicine_brand_to_generic",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_professional_medicine_g2b": {
      "task": "mmlu_professional_medicine_g2b",
      "dataset_path": "AIM-Harvard/hails_mmlu_no_train_professional_medicine_generic_to_brand",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_professional_medicine_orig_filtered": {
      "task": "mmlu_professional_medicine_orig_filtered",
      "dataset_path": "AIM-Harvard/hails_mmlu_no_train_professional_medicine_original",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    }
  },
  "versions": {
    "b4b": "N/A",
    "b4bqa": "Yaml",
    "medmcqa_b2g": "Yaml",
    "medmcqa_g2b": "Yaml",
    "medmcqa_orig_filtered": "Yaml",
    "medqa_4options_b2g": "Yaml",
    "medqa_4options_g2b": "Yaml",
    "medqa_4options_orig_filtered": "Yaml",
    "mmlu_professional_medicine_b2g": 0.0,
    "mmlu_professional_medicine_g2b": 0.0,
    "mmlu_professional_medicine_orig_filtered": 0.0
  },
  "n-shot": {
    "b4b": 0,
    "b4bqa": 0,
    "medmcqa_b2g": 0,
    "medmcqa_g2b": 0,
    "medmcqa_orig_filtered": 0,
    "medqa_4options_b2g": 0,
    "medqa_4options_g2b": 0,
    "medqa_4options_orig_filtered": 0,
    "mmlu_professional_medicine_b2g": 0,
    "mmlu_professional_medicine_g2b": 0,
    "mmlu_professional_medicine_orig_filtered": 0
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=mistralai/Mistral-7B-v0.3",
    "batch_size": "auto:64",
    "batch_sizes": [
      32,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64
    ],
    "device": "cuda:0",
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": null
  },
  "git_hash": "81a30781"
}