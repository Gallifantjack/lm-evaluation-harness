{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define datasets and directions\n",
    "datasets = [\n",
    "    \"b4bqa\"\n",
    "    # orig filtered\n",
    "    \"medmcqa_orig_filtered\",\n",
    "    \"medqa_4options_orig_filtered\",\n",
    "    # g2b\n",
    "    \"medqa_4options_g2b\",\n",
    "    \"medqa_4options_g2b\",\n",
    "]\n",
    "\n",
    "models = [\n",
    "    \"microsoft/phi-1\",\n",
    "    \"microsoft/phi-1_5\",\n",
    "    \"microsoft/phi-2\",\n",
    "    \"microsoft/Phi-3-medium-4k-instruct\",\n",
    "    \"mistralai/Mistral-7B-v0.3\",\n",
    "    # \"Qwen/Qwen1.5-7B\",\n",
    "    \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"meta-llama/Meta-Llama-3-8B\",\n",
    "    \"mistralai/Mixtral-8x7B-v0.1\",\n",
    "    \"mistralai/Mixtral-8x22B-v0.1\",\n",
    "    \"meta-llama/Llama-2-70B-hf\",\n",
    "    \"meta-llama/Meta-Llama-3-70B\",\n",
    "    # \"Qwen/Qwen1.5-72B\",\n",
    "    \"CohereForAI/c4ai-command-r-plus\",\n",
    "    \"CohereForAI/aya-23-35B\",\n",
    "    \"Qwen/Qwen2-72B\",\n",
    "    \"Qwen/Qwen2-7B\",\n",
    "    # \"Qwen/Qwen1.5-110B\",\n",
    "    \"01-ai/Yi-1.5-34B\",\n",
    "]\n",
    "\n",
    "# Define a dictionary to map the original dataset names to the new names\n",
    "model_name_map = {\n",
    "    \"microsoft-phi-1\": \"phi-1\",\n",
    "    \"microsoft-phi-1_5\": \"phi-1_5\",\n",
    "    \"microsoft-phi-2\": \"phi-2\",\n",
    "    \"microsoft-Phi-3-medium-4k-instruct\": \"phi-3-medium\",\n",
    "    \"CohereForAI-aya-23-35B\": \"c4ai-aya-23-35B\",\n",
    "    \"CohereForAI-c4ai-command-r-plus\": \"c4ai-r-plus\",\n",
    "    \"meta-llama-Llama-2-70B-hf\": \"llama-2-70B\",\n",
    "    \"meta-llama-Llama-2-7b-hf\": \"llama-2-7B\",\n",
    "    \"meta-llama-Meta-Llama-3-70B\": \"llama-3-70B\",\n",
    "    \"meta-llama-Meta-Llama-3-8B\": \"llama-3-8B\",\n",
    "    \"mistralai-Mixtral-8x22B-v0.1\": \"mixtral-8x22B\",\n",
    "    \"mistralai-Mixtral-8x7B-v0.1\": \"mixtral-8x7B\",\n",
    "    \"mistralai-Mistral-7B-v0.3\": \"mistral-7B\",\n",
    "    # \"Qwen-Qwen1.5-72B\": \"qwen1.5-72B\",\n",
    "    # \"Qwen-Qwen1.5-7B\": \"qwen1.5-7B\",\n",
    "    \"Qwen-Qwen2-72B\": \"qwen1.5-72B\",\n",
    "    \"Qwen-Qwen2-7B\": \"qwen1.5-7B\",\n",
    "    # \"Qwen-Qwen1.5-110B\": \"qwen1.5-110B\",\n",
    "    \"01-ai-Yi-1.5-34B\": \"yi-1.5-34B\",\n",
    "}\n",
    "\n",
    "\n",
    "model_size_map = {\n",
    "    \"phi-1\": \"1.3\",\n",
    "    \"phi-1_5\": \"1.3\",\n",
    "    \"phi-2\": \"2.7\",\n",
    "    \"phi-3-medium\": \"14\",\n",
    "    \"c4ai-aya-23-35B\": \"35\",\n",
    "    \"c4ai-r-plus\": \"104\",\n",
    "    \"llama-2-70B\": \"70\",\n",
    "    \"llama-2-7B\": \"7\",\n",
    "    \"llama-3-70B\": \"70\",\n",
    "    \"llama-3-8B\": \"8\",\n",
    "    \"mixtral-8x22B\": \"176\",\n",
    "    \"mixtral-8x7B\": \"56\",\n",
    "    \"mistral-7B\": \"7\",\n",
    "    # \"qwen1.5-72B\": \"72\",\n",
    "    # \"qwen1.5-7B\": \"7\",\n",
    "    \"qwen2-72B\": \"72\",\n",
    "    \"qwen2-7B\": \"7\",\n",
    "    # \"qwen1.5-110B\": \"110\",\n",
    "    \"yi-1.5-34B\": \"34\",\n",
    "}\n",
    "\n",
    "\n",
    "replacement_directions = [\"generic_to_brand\", \"none\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_results(model, direction):\n",
    "    \"\"\"\n",
    "    Load the model results from a JSON file.\n",
    "\n",
    "    Args:\n",
    "    model (str): The model name.\n",
    "    direction (str): The direction of replacements (e.g., brand_to_generic, generic_to_brand).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the model results.\n",
    "    \"\"\"\n",
    "    results_file_path = f\"b4b/{model}_results.json\"\n",
    "\n",
    "    if os.path.exists(results_file_path):\n",
    "        with open(results_file_path, \"r\") as file:\n",
    "            results_data = json.load(file)\n",
    "\n",
    "        results = results_data[\"results\"]\n",
    "        results_list = []\n",
    "\n",
    "        for dataset, metrics in results.items():\n",
    "            for metric, value in metrics.items():\n",
    "                if metric.startswith(\"acc\"):\n",
    "                    metric_name = metric.split(\",\")[0]\n",
    "                    results_list.append([dataset, metric_name, value])\n",
    "\n",
    "        df_results = pd.DataFrame(results_list, columns=[\"Dataset\", \"Metric\", \"Value\"])\n",
    "        df_results[\"Model\"] = model\n",
    "        df_results[\"Dataset\"] = df_results[\"Dataset\"]\n",
    "\n",
    "        return df_results\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"Dataset\", \"Metric\", \"Value\", \"Model\"])\n",
    "\n",
    "\n",
    "def process_results(results_df):\n",
    "    # Wrangle names to get pairs\n",
    "    results_df[\"Direction\"] = results_df[\"Dataset\"].apply(\n",
    "        lambda x: (\n",
    "            \"brand_to_generic\"\n",
    "            if \"b2g\" in x\n",
    "            else \"generic_to_brand\" if \"g2b\" in x else \"none\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # If _b2g, _g2b, or b4b_ in name remove it from the name\n",
    "    for term in [\"_b2g\", \"_g2b\", \"b4b_\", \"_orig_filtered\"]:\n",
    "        results_df[\"Dataset\"] = results_df[\"Dataset\"].apply(\n",
    "            lambda x: x.replace(term, \"\")\n",
    "        )\n",
    "\n",
    "    # Filter the results DataFrame to include only accuracy metrics\n",
    "    results_df_filtered = results_df[results_df[\"Metric\"] == \"acc\"]\n",
    "\n",
    "    # filter out datasets if not contain medmcqa, medqa\n",
    "    results_df_filtered = results_df_filtered[\n",
    "        results_df_filtered[\"Dataset\"].str.contains(\"medmcqa|medqa\")\n",
    "    ]\n",
    "\n",
    "    # Pivot the DataFrame to have directions as columns\n",
    "    pivot_results = results_df_filtered.pivot_table(\n",
    "        index=[\"Dataset\", \"Model\"], columns=\"Direction\", values=\"Value\"\n",
    "    ).reset_index()\n",
    "\n",
    "    # Replace 'b4b' with NaN\n",
    "    pivot_results.replace(\"b4b\", np.nan, inplace=True)\n",
    "\n",
    "    # Drop the row with NaN\n",
    "    pivot_results.dropna(subset=[\"Dataset\"], inplace=True)\n",
    "\n",
    "    # Calculate the average for each model\n",
    "    average_df = (\n",
    "        pivot_results.groupby(\"Model\")[[\"generic_to_brand\", \"none\"]]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Assign the averages to 'b4b' dataset\n",
    "    average_df[\"Dataset\"] = \"b4b\"\n",
    "\n",
    "    # Append the averages to the original DataFrame\n",
    "    pivot_results = pd.concat([pivot_results, average_df], ignore_index=True)\n",
    "\n",
    "    return pivot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Results found:\n",
      "['microsoft-phi-1' 'microsoft-phi-1_5' 'microsoft-phi-2'\n",
      " 'microsoft-Phi-3-medium-4k-instruct' 'mistralai-Mistral-7B-v0.3'\n",
      " 'meta-llama-Llama-2-7b-hf' 'meta-llama-Meta-Llama-3-8B'\n",
      " 'mistralai-Mixtral-8x7B-v0.1' 'mistralai-Mixtral-8x22B-v0.1'\n",
      " 'meta-llama-Llama-2-70B-hf' 'meta-llama-Meta-Llama-3-70B'\n",
      " 'CohereForAI-c4ai-command-r-plus' 'CohereForAI-aya-23-35B'\n",
      " 'Qwen-Qwen2-72B' 'Qwen-Qwen2-7B' '01-ai-Yi-1.5-34B']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Direction</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>generic_to_brand</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>b4b</td>\n",
       "      <td>c4ai-aya-23-35B</td>\n",
       "      <td>0.482234</td>\n",
       "      <td>0.519659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>b4b</td>\n",
       "      <td>c4ai-r-plus</td>\n",
       "      <td>0.528758</td>\n",
       "      <td>0.609059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>b4b</td>\n",
       "      <td>llama-2-70B</td>\n",
       "      <td>0.493113</td>\n",
       "      <td>0.536627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>b4b</td>\n",
       "      <td>llama-2-7B</td>\n",
       "      <td>0.341498</td>\n",
       "      <td>0.357485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>b4b</td>\n",
       "      <td>llama-3-70B</td>\n",
       "      <td>0.697090</td>\n",
       "      <td>0.766466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>b4b</td>\n",
       "      <td>llama-3-8B</td>\n",
       "      <td>0.539500</td>\n",
       "      <td>0.600210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>b4b</td>\n",
       "      <td>mistral-7B</td>\n",
       "      <td>0.484766</td>\n",
       "      <td>0.550356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>b4b</td>\n",
       "      <td>mixtral-8x22B</td>\n",
       "      <td>0.646210</td>\n",
       "      <td>0.709154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>b4b</td>\n",
       "      <td>mixtral-8x7B</td>\n",
       "      <td>0.577563</td>\n",
       "      <td>0.636882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>b4b</td>\n",
       "      <td>phi-1</td>\n",
       "      <td>0.229155</td>\n",
       "      <td>0.233808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>b4b</td>\n",
       "      <td>phi-1_5</td>\n",
       "      <td>0.332649</td>\n",
       "      <td>0.325579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>b4b</td>\n",
       "      <td>phi-2</td>\n",
       "      <td>0.397213</td>\n",
       "      <td>0.430784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>b4b</td>\n",
       "      <td>phi-3-medium</td>\n",
       "      <td>0.568920</td>\n",
       "      <td>0.654397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>b4b</td>\n",
       "      <td>qwen1.5-72B</td>\n",
       "      <td>0.728129</td>\n",
       "      <td>0.766352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>b4b</td>\n",
       "      <td>qwen1.5-7B</td>\n",
       "      <td>0.544381</td>\n",
       "      <td>0.612502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>b4b</td>\n",
       "      <td>yi-1.5-34B</td>\n",
       "      <td>0.597792</td>\n",
       "      <td>0.669016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>c4ai-aya-23-35B</td>\n",
       "      <td>0.485632</td>\n",
       "      <td>0.528736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>c4ai-r-plus</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.614943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>llama-2-70B</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.522989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>llama-2-7B</td>\n",
       "      <td>0.339080</td>\n",
       "      <td>0.341954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>llama-3-70B</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.781609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>llama-3-8B</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>0.591954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>mistral-7B</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.568966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>mixtral-8x22B</td>\n",
       "      <td>0.617816</td>\n",
       "      <td>0.704023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>mixtral-8x7B</td>\n",
       "      <td>0.554598</td>\n",
       "      <td>0.649425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>phi-1</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.258621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>phi-1_5</td>\n",
       "      <td>0.316092</td>\n",
       "      <td>0.304598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>phi-2</td>\n",
       "      <td>0.376437</td>\n",
       "      <td>0.422414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>phi-3-medium</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>qwen1.5-72B</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.778736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>qwen1.5-7B</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.635057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>yi-1.5-34B</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.692529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>c4ai-aya-23-35B</td>\n",
       "      <td>0.478836</td>\n",
       "      <td>0.510582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>c4ai-r-plus</td>\n",
       "      <td>0.566138</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>llama-2-70B</td>\n",
       "      <td>0.526455</td>\n",
       "      <td>0.550265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>llama-2-7B</td>\n",
       "      <td>0.343915</td>\n",
       "      <td>0.373016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>llama-3-70B</td>\n",
       "      <td>0.727513</td>\n",
       "      <td>0.751323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>llama-3-8B</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.608466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>mistral-7B</td>\n",
       "      <td>0.486772</td>\n",
       "      <td>0.531746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>mixtral-8x22B</td>\n",
       "      <td>0.674603</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>mixtral-8x7B</td>\n",
       "      <td>0.600529</td>\n",
       "      <td>0.624339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>phi-1</td>\n",
       "      <td>0.216931</td>\n",
       "      <td>0.208995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>phi-1_5</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.346561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>phi-2</td>\n",
       "      <td>0.417989</td>\n",
       "      <td>0.439153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>phi-3-medium</td>\n",
       "      <td>0.534392</td>\n",
       "      <td>0.584656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>qwen1.5-72B</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.753968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>qwen1.5-7B</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.589947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>medqa_4options</td>\n",
       "      <td>yi-1.5-34B</td>\n",
       "      <td>0.597884</td>\n",
       "      <td>0.645503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Direction         Dataset            Model  generic_to_brand      none\n",
       "33                    b4b  c4ai-aya-23-35B          0.482234  0.519659\n",
       "34                    b4b      c4ai-r-plus          0.528758  0.609059\n",
       "37                    b4b      llama-2-70B          0.493113  0.536627\n",
       "38                    b4b       llama-2-7B          0.341498  0.357485\n",
       "39                    b4b      llama-3-70B          0.697090  0.766466\n",
       "40                    b4b       llama-3-8B          0.539500  0.600210\n",
       "45                    b4b       mistral-7B          0.484766  0.550356\n",
       "46                    b4b    mixtral-8x22B          0.646210  0.709154\n",
       "47                    b4b     mixtral-8x7B          0.577563  0.636882\n",
       "42                    b4b            phi-1          0.229155  0.233808\n",
       "43                    b4b          phi-1_5          0.332649  0.325579\n",
       "44                    b4b            phi-2          0.397213  0.430784\n",
       "41                    b4b     phi-3-medium          0.568920  0.654397\n",
       "35                    b4b      qwen1.5-72B          0.728129  0.766352\n",
       "36                    b4b       qwen1.5-7B          0.544381  0.612502\n",
       "32                    b4b       yi-1.5-34B          0.597792  0.669016\n",
       "1                 medmcqa  c4ai-aya-23-35B          0.485632  0.528736\n",
       "2                 medmcqa      c4ai-r-plus          0.491379  0.614943\n",
       "5                 medmcqa      llama-2-70B          0.459770  0.522989\n",
       "6                 medmcqa       llama-2-7B          0.339080  0.341954\n",
       "7                 medmcqa      llama-3-70B          0.666667  0.781609\n",
       "8                 medmcqa       llama-3-8B          0.528736  0.591954\n",
       "13                medmcqa       mistral-7B          0.482759  0.568966\n",
       "14                medmcqa    mixtral-8x22B          0.617816  0.704023\n",
       "15                medmcqa     mixtral-8x7B          0.554598  0.649425\n",
       "10                medmcqa            phi-1          0.241379  0.258621\n",
       "11                medmcqa          phi-1_5          0.316092  0.304598\n",
       "12                medmcqa            phi-2          0.376437  0.422414\n",
       "9                 medmcqa     phi-3-medium          0.603448  0.724138\n",
       "3                 medmcqa      qwen1.5-72B          0.715517  0.778736\n",
       "4                 medmcqa       qwen1.5-7B          0.551724  0.635057\n",
       "0                 medmcqa       yi-1.5-34B          0.597701  0.692529\n",
       "17         medqa_4options  c4ai-aya-23-35B          0.478836  0.510582\n",
       "18         medqa_4options      c4ai-r-plus          0.566138  0.603175\n",
       "21         medqa_4options      llama-2-70B          0.526455  0.550265\n",
       "22         medqa_4options       llama-2-7B          0.343915  0.373016\n",
       "23         medqa_4options      llama-3-70B          0.727513  0.751323\n",
       "24         medqa_4options       llama-3-8B          0.550265  0.608466\n",
       "29         medqa_4options       mistral-7B          0.486772  0.531746\n",
       "30         medqa_4options    mixtral-8x22B          0.674603  0.714286\n",
       "31         medqa_4options     mixtral-8x7B          0.600529  0.624339\n",
       "26         medqa_4options            phi-1          0.216931  0.208995\n",
       "27         medqa_4options          phi-1_5          0.349206  0.346561\n",
       "28         medqa_4options            phi-2          0.417989  0.439153\n",
       "25         medqa_4options     phi-3-medium          0.534392  0.584656\n",
       "19         medqa_4options      qwen1.5-72B          0.740741  0.753968\n",
       "20         medqa_4options       qwen1.5-7B          0.537037  0.589947\n",
       "16         medqa_4options       yi-1.5-34B          0.597884  0.645503"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store the final results\n",
    "results_df = pd.DataFrame(columns=[\"Dataset\", \"Metric\", \"Value\", \"Model\"])\n",
    "\n",
    "# replace model / with - in the model name\n",
    "for i in range(len(models)):\n",
    "    models[i] = models[i].replace(\"/\", \"-\")\n",
    "\n",
    "# Load and store the model results\n",
    "for model in models:\n",
    "    for direction in replacement_directions:\n",
    "        df_model_results = load_model_results(model, direction)\n",
    "        if not df_model_results.empty:\n",
    "            results_df = pd.concat([results_df, df_model_results], ignore_index=True)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_output_file_path = \"tables/all_model_results.csv\"\n",
    "results_df.to_csv(results_output_file_path, index=False)\n",
    "\n",
    "print(\"\\nModel Results found:\")\n",
    "print(results_df[\"Model\"].unique())\n",
    "\n",
    "processed_results = process_results(results_df)\n",
    "\n",
    "# Assume processed_results is a pandas DataFrame and 'Model' is one of its columns\n",
    "processed_results[\"Model\"] = (\n",
    "    processed_results[\"Model\"].map(model_name_map).fillna(processed_results[\"Model\"])\n",
    ")\n",
    "\n",
    "\n",
    "# sort by dataset and model\n",
    "processed_results = processed_results.sort_values(by=[\"Dataset\", \"Model\"])\n",
    "\n",
    "processed_results_output_file_path = \"tables/processed_model_results.csv\"\n",
    "\n",
    "# Save the processed results to a CSV file\n",
    "processed_results.to_csv(processed_results_output_file_path, index=False)\n",
    "processed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get b4b qa results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.196429</td>\n",
       "      <td>microsoft-phi-1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.280134</td>\n",
       "      <td>microsoft-phi-1_5</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.474888</td>\n",
       "      <td>microsoft-phi-2</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.703125</td>\n",
       "      <td>mistralai-Mistral-7B-v0.3</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.368304</td>\n",
       "      <td>meta-llama-Llama-2-7b-hf</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.827009</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.699777</td>\n",
       "      <td>microsoft-Phi-3-medium-4k-instruct</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.851562</td>\n",
       "      <td>01-ai-Yi-1.5-34B</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.784040</td>\n",
       "      <td>CohereForAI-aya-23-35B</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.861049</td>\n",
       "      <td>mistralai-Mixtral-8x7B-v0.1</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.770089</td>\n",
       "      <td>meta-llama-Llama-2-70B-hf</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.901228</td>\n",
       "      <td>meta-llama-Meta-Llama-3-70B</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0.849330</td>\n",
       "      <td>CohereForAI-c4ai-command-r-plus</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.877232</td>\n",
       "      <td>mistralai-Mixtral-8x22B-v0.1</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0.910156</td>\n",
       "      <td>Qwen-Qwen2-72B</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>0.804129</td>\n",
       "      <td>Qwen-Qwen2-7B</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Value                               Model  Model Size\n",
       "4    0.196429                     microsoft-phi-1         1.3\n",
       "52   0.280134                   microsoft-phi-1_5         1.3\n",
       "100  0.474888                     microsoft-phi-2         2.7\n",
       "196  0.703125           mistralai-Mistral-7B-v0.3         7.0\n",
       "244  0.368304            meta-llama-Llama-2-7b-hf         7.0\n",
       "292  0.827009          meta-llama-Meta-Llama-3-8B         8.0\n",
       "148  0.699777  microsoft-Phi-3-medium-4k-instruct        14.0\n",
       "724  0.851562                    01-ai-Yi-1.5-34B        34.0\n",
       "580  0.784040              CohereForAI-aya-23-35B        35.0\n",
       "340  0.861049         mistralai-Mixtral-8x7B-v0.1        56.0\n",
       "436  0.770089           meta-llama-Llama-2-70B-hf        70.0\n",
       "484  0.901228         meta-llama-Meta-Llama-3-70B        70.0\n",
       "532  0.849330     CohereForAI-c4ai-command-r-plus       104.0\n",
       "388  0.877232        mistralai-Mixtral-8x22B-v0.1       176.0\n",
       "628  0.910156                      Qwen-Qwen2-72B         NaN\n",
       "676  0.804129                       Qwen-Qwen2-7B         NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df\n",
    "# keep only rows where Dataset=='b4bqa' and Metric=='acc'\n",
    "b4bqa_results = results_df[\n",
    "    (results_df[\"Dataset\"] == \"b4bqa\") & (results_df[\"Metric\"] == \"acc\")\n",
    "]\n",
    "# deduplicate the results\n",
    "b4bqa_results = b4bqa_results.drop_duplicates(subset=[\"Model\"])\n",
    "# sort the results by Model size\n",
    "b4bqa_results[\"Model Size\"] = (\n",
    "    b4bqa_results[\"Model\"].map(model_name_map).map(model_size_map)\n",
    ")\n",
    "b4bqa_results[\"Model Size\"] = pd.to_numeric(b4bqa_results[\"Model Size\"])\n",
    "b4bqa_results = b4bqa_results.sort_values(by=\"Model Size\")\n",
    "\n",
    "# drop column direction and metric\n",
    "b4bqa_results = b4bqa_results.drop(columns=[\"Direction\", \"Metric\", \"Dataset\"])\n",
    "\n",
    "b4bqa_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Model\", y=\"Value\", data=b4bqa_results, palette=\"viridis\")\n",
    "\n",
    "plt.title(\"Acc for MCQA testing drug generic and brand terms\")\n",
    "plt.xlabel(\"Model (ranked by model size)\")\n",
    "plt.ylabel(\"Accuracy (0-1)\")\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latex tables\n",
    "\n",
    "#### Dataset | Model | brand_to_generic | generic_to_brand | none\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX table\n",
    "latex_table = processed_results.to_latex(index=False, float_format=\"%.3f\")\n",
    "\n",
    "# Save LaTeX table to a file\n",
    "with open(\"tables/model_results_table.tex\", \"w\") as f:\n",
    "    f.write(latex_table)\n",
    "# Print the LaTeX table\n",
    "## # Dataset | Model | brand_to_generic | generic_to_brand | none\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model | none | generic_to_brand | Average | Difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the 'b4b' dataset\n",
    "b4b_results = processed_results[processed_results[\"Dataset\"] == \"b4b\"].copy()\n",
    "\n",
    "# Calculate the average of original (none) and generic to brand\n",
    "b4b_results[\"Average\"] = b4b_results[[\"none\", \"generic_to_brand\"]].mean(axis=1)\n",
    "\n",
    "# Calculate the difference\n",
    "b4b_results[\"Difference\"] = b4b_results[\"generic_to_brand\"] - b4b_results[\"none\"]\n",
    "\n",
    "# Select relevant columns for the LaTeX table\n",
    "b4b_results = b4b_results[\n",
    "    [\"Model\", \"none\", \"generic_to_brand\", \"Average\", \"Difference\"]\n",
    "]\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table_b4b = b4b_results.to_latex(index=False, float_format=\"%.3f\")\n",
    "\n",
    "# Save LaTeX table to a file\n",
    "with open(\"tables/b4b_results_table.tex\", \"w\") as f:\n",
    "    f.write(latex_table_b4b)\n",
    "\n",
    "# Print the LaTeX table\n",
    "## # Model | none | generic_to_brand | Average | Difference\n",
    "print(latex_table_b4b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise difference in performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the differences\n",
    "processed_results[\"Diff_generic_to_brand\"] = (\n",
    "    processed_results[\"generic_to_brand\"] - processed_results[\"none\"]\n",
    ")\n",
    "\n",
    "# Melt the DataFrame for plotting\n",
    "melted_results = processed_results.melt(\n",
    "    id_vars=[\"Dataset\", \"Model\"],\n",
    "    value_vars=[\"Diff_generic_to_brand\"],\n",
    "    var_name=\"Direction\",\n",
    "    value_name=\"Accuracy Difference\",\n",
    ")\n",
    "\n",
    "melted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to only include 'Diff_generic_to_brand' direction\n",
    "filtered_results = melted_results[\n",
    "    melted_results[\"Direction\"] == \"Diff_generic_to_brand\"\n",
    "]\n",
    "\n",
    "# Create a new column 'Model Size' in the DataFrame\n",
    "filtered_results[\"Model Size\"] = filtered_results[\"Model\"].map(model_size_map)\n",
    "filtered_results[\"Model Size\"] = pd.to_numeric(filtered_results[\"Model Size\"])\n",
    "\n",
    "# Create bar plots for each task with filtered data\n",
    "tasks = filtered_results[\"Dataset\"].unique()\n",
    "num_tasks = len(tasks)\n",
    "ncols = 3  # Number of columns in the grid\n",
    "nrows = (num_tasks // ncols) + (num_tasks % ncols > 0)  # Number of rows needed\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows, ncols=ncols, figsize=(18, nrows * 5), constrained_layout=True\n",
    ")\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "for i, task in enumerate(tasks):\n",
    "    ax = axes[i]\n",
    "    task_data = filtered_results[filtered_results[\"Dataset\"] == task]\n",
    "    task_data = task_data.sort_values(\"Model Size\")  # Sort by Model Size\n",
    "    sns.barplot(\n",
    "        x=\"Model\",\n",
    "        y=\"Accuracy Difference\",\n",
    "        data=task_data,\n",
    "        palette=\"viridis\",\n",
    "        ax=ax,\n",
    "        order=task_data[\"Model\"],\n",
    "    )\n",
    "\n",
    "    # Add labels on top of the bars\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt=\"%.2f\", label_type=\"edge\", padding=3)\n",
    "\n",
    "    ax.set_title(f\"Accuracy Difference for {task} (Generic to Brand)\")\n",
    "    ax.set_xlabel(\"Model\")\n",
    "    ax.set_ylabel(\"Accuracy Difference\")\n",
    "    ax.set_ylim(-0.2, 0.1)  # Adjust the y-axis limits as needed\n",
    "\n",
    "    # Rotate the x-axis labels for better readability\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig(\"plots/accuracy_difference_generic_to_brand.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique tasks\n",
    "tasks = processed_results[\"Dataset\"].unique()\n",
    "\n",
    "for task in tasks:\n",
    "    task_data = processed_results[processed_results[\"Dataset\"] == task]\n",
    "\n",
    "    # Setting up the figure and axis for generic_to_brand scatter plot\n",
    "    plt.figure(figsize=(9, 8))\n",
    "    ax2 = sns.scatterplot(\n",
    "        data=task_data,\n",
    "        x=\"none\",\n",
    "        y=\"generic_to_brand\",\n",
    "        hue=\"Model\",\n",
    "        style=\"Model\",\n",
    "        palette=\"viridis\",\n",
    "        s=100,\n",
    "    )\n",
    "    ax2.plot([0, 1], [0, 1], ls=\"--\", c=\".3\")  # Diagonal line\n",
    "    ax2.set_title(f\"Acc of Original vs Generic to Brand for {task}\")\n",
    "    ax2.set_xlabel(\"Acc of No Replacement\")\n",
    "    ax2.set_ylabel(\"Acc of Generic to Brand Replacement\")\n",
    "\n",
    "    # Configure and place the legend outside the plot with a grey background\n",
    "    legend = ax2.legend(\n",
    "        title=\"Model\", bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0, frameon=True\n",
    "    )\n",
    "    legend.get_frame().set_color(\"#f0f0f0\")  # Set legend background color\n",
    "    plt.setp(legend.get_title(), weight=\"bold\")  # Make legend title bold\n",
    "    plt.savefig(f\"plots/{task}_generic_to_brand.png\")\n",
    "    plt.show()  # Display the plot in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assume 'processed_results' is your DataFrame\n",
    "processed_results[\"Model_g2b_detail\"] = processed_results.apply(\n",
    "    lambda x: f\"{x['Model']} | g2b: {x['generic_to_brand']:.2f}, orig: {x['none']:.2f}\",\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Get the unique tasks\n",
    "tasks = processed_results[\"Dataset\"].unique()\n",
    "\n",
    "for task in tasks:\n",
    "    task_data = processed_results[processed_results[\"Dataset\"] == task]\n",
    "\n",
    "    # Scatter plot for generic_to_brand vs none\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax2 = sns.scatterplot(\n",
    "        data=task_data,\n",
    "        x=\"none\",\n",
    "        y=\"generic_to_brand\",\n",
    "        hue=\"Model_g2b_detail\",  # Use detailed label for hue\n",
    "        style=\"Model_g2b_detail\",  # Use detailed label for style\n",
    "        palette=\"viridis\",\n",
    "        s=100,\n",
    "    )\n",
    "    ax2.set_xlim([0.2, 0.9])  # Set x-axis range\n",
    "    ax2.set_ylim([0.2, 0.9])\n",
    "    ax2.plot([0, 1], [0, 1], ls=\"--\", c=\".3\")  # Diagonal reference line\n",
    "    ax2.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax2.set_title(f\"Acc of Original vs Generic to Brand for {task}\", loc=\"center\")\n",
    "    ax2.set_xlabel(\"Acc with No Replacement (0-1)\")\n",
    "    ax2.set_ylabel(\"Acc with Generic to Brand Replacement (0-1)\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Configure and place the legend outside the plot\n",
    "    legend = ax2.legend(\n",
    "        title=\"Model Details\",\n",
    "        bbox_to_anchor=(1.05, 1),\n",
    "        loc=2,\n",
    "        borderaxespad=0.0,\n",
    "        frameon=True,\n",
    "    )\n",
    "    legend.get_frame().set_color(\"#f0f0f0\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{task}_generic_to_brand.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in keywords count for each dataset (raw file in b4b repo)\n",
    "keywords_count = pd.read_csv(\"keywords_count_test.csv\")\n",
    "\n",
    "keywords_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"meta-llama/Meta-Llama-3-8B\",\n",
    "    \"meta-llama/Meta-Llama-3-70B\",\n",
    "    \"aaditya/Llama3-OpenBioLLM-70B\",\n",
    "    \"johnsnowlabs/JSL-MedLlama-3-8B-v9\",\n",
    "    \"ProbeMedicalYonseiMAILab/medllama3-v20\",\n",
    "]\n",
    "\n",
    "model_name_map = {\n",
    "    \"meta-llama-Meta-Llama-3-8B\": \"llama-3-8B\",\n",
    "    \"meta-llama-Meta-Llama-3-70B\": \"llama-3-70B\",\n",
    "    \"aaditya-Llama3-OpenBioLLM-70B\": \"llama-3-70B-sft1\",\n",
    "    \"johnsnowlabs-JSL-MedLlama-3-8B-v9\": \"llama-3-8B-sft1\",\n",
    "    \"ProbeMedicalYonseiMAILab-medllama3-v20\": \"llama-3-8B-sft2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the final results\n",
    "results_df = pd.DataFrame(columns=[\"Dataset\", \"Metric\", \"Value\", \"Model\"])\n",
    "\n",
    "# replace model / with - in the model name\n",
    "for i in range(len(models)):\n",
    "    models[i] = models[i].replace(\"/\", \"-\")\n",
    "\n",
    "# Load and store the model results\n",
    "for model in models:\n",
    "    for direction in replacement_directions:\n",
    "        df_model_results = load_model_results(model, direction)\n",
    "        if not df_model_results.empty:\n",
    "            results_df = pd.concat([results_df, df_model_results], ignore_index=True)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "# results_output_file_path = \"tables/all_model_results.csv\"\n",
    "# results_df.to_csv(results_output_file_path, index=False)\n",
    "\n",
    "print(\"\\nModel Results found:\")\n",
    "print(results_df[\"Model\"].unique())\n",
    "\n",
    "processed_results = process_results(results_df)\n",
    "# processed_results\n",
    "# # Assume processed_results is a pandas DataFrame and 'Model' is one of its columns\n",
    "processed_results[\"Model\"] = (\n",
    "    processed_results[\"Model\"].map(model_name_map).fillna(processed_results[\"Model\"])\n",
    ")\n",
    "\n",
    "processed_results\n",
    "\n",
    "# # sort by dataset and model\n",
    "# processed_results = processed_results.sort_values(by=[\"Dataset\", \"Model\"])\n",
    "\n",
    "# # processed_results_output_file_path = \"tables/processed_model_results.csv\"\n",
    "\n",
    "# # Save the processed results to a CSV file\n",
    "# # processed_results.to_csv(processed_results_output_file_path, index=False)\n",
    "# processed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnb_39_117",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
