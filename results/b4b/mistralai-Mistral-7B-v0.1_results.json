{
  "results": {
    "b4b": {
      "acc,none": 0.46366650876361915,
      "acc_stderr,none": 0.07734244685954582,
      "acc_norm,none": 0.463107485130192,
      "acc_norm_stderr,none": 0.00024675669553543024,
      "alias": "b4b"
    },
    "b4b_mmlu_anatomy": {
      "alias": " - anatomy (mmlu)",
      "acc,none": 0.562962962962963,
      "acc_stderr,none": 0.042849586397534
    },
    "b4b_mmlu_clinical_knowledge": {
      "alias": " - clinical_knowledge (mmlu)",
      "acc,none": 0.6754716981132075,
      "acc_stderr,none": 0.028815615713432118
    },
    "b4b_mmlu_college_biology": {
      "alias": " - college_biology (mmlu)",
      "acc,none": 0.7013888888888888,
      "acc_stderr,none": 0.038270523579507554
    },
    "b4b_mmlu_college_medicine": {
      "alias": " - college_medicine (mmlu)",
      "acc,none": 0.6127167630057804,
      "acc_stderr,none": 0.03714325906302065
    },
    "b4b_mmlu_medical_genetics": {
      "alias": " - medical_genetics (mmlu)",
      "acc,none": 0.69,
      "acc_stderr,none": 0.04648231987117316
    },
    "b4b_mmlu_professional_medicine": {
      "alias": " - professional_medicine (mmlu)",
      "acc,none": 0.6617647058823529,
      "acc_stderr,none": 0.028739328513983583
    },
    "medmcqa": {
      "acc,none": 0.45589289983265596,
      "acc_stderr,none": 0.007701611309710368,
      "acc_norm,none": 0.45589289983265596,
      "acc_norm_stderr,none": 0.007701611309710368,
      "alias": " - medmcqa"
    },
    "medmcqa_b2g": {
      "acc,none": 0.45589289983265596,
      "acc_stderr,none": 0.00770161130971037,
      "acc_norm,none": 0.45589289983265596,
      "acc_norm_stderr,none": 0.00770161130971037,
      "alias": " - medmcqa_b2g"
    },
    "medmcqa_g2b": {
      "acc,none": 0.45589289983265596,
      "acc_stderr,none": 0.007701611309710368,
      "acc_norm,none": 0.45589289983265596,
      "acc_norm_stderr,none": 0.007701611309710368,
      "alias": " - medmcqa_g2b"
    },
    "medqa_4options": {
      "acc,none": 0.48860958366064416,
      "acc_stderr,none": 0.014015665606820582,
      "acc_norm,none": 0.48860958366064416,
      "acc_norm_stderr,none": 0.014015665606820582,
      "alias": " - medqa_4options"
    },
    "medqa_4options_b2g": {
      "acc,none": 0.48939512961508247,
      "acc_stderr,none": 0.014016150183915747,
      "acc_norm,none": 0.48939512961508247,
      "acc_norm_stderr,none": 0.014016150183915747,
      "alias": " - medqa_4options_b2g"
    },
    "medqa_4options_g2b": {
      "acc,none": 0.48860958366064416,
      "acc_stderr,none": 0.014015665606820576,
      "acc_norm,none": 0.48860958366064416,
      "acc_norm_stderr,none": 0.014015665606820576,
      "alias": " - medqa_4options_g2b"
    },
    "mmlu_anatomy_b2g": {
      "acc,none": 0.3111111111111111,
      "acc_stderr,none": 0.039992628766177214,
      "alias": " - mmlu_anatomy_b2g"
    },
    "mmlu_anatomy_g2b": {
      "acc,none": 0.3111111111111111,
      "acc_stderr,none": 0.03999262876617723,
      "alias": " - mmlu_anatomy_g2b"
    },
    "mmlu_clinical_knowledge_b2g": {
      "acc,none": 0.2641509433962264,
      "acc_stderr,none": 0.0271342916287417,
      "alias": " - mmlu_clinical_knowledge_b2g"
    },
    "mmlu_clinical_knowledge_g2b": {
      "acc,none": 0.2641509433962264,
      "acc_stderr,none": 0.02713429162874171,
      "alias": " - mmlu_clinical_knowledge_g2b"
    },
    "mmlu_college_biology_b2g": {
      "acc,none": 0.3263888888888889,
      "acc_stderr,none": 0.03921067198982266,
      "alias": " - mmlu_college_biology_b2g"
    },
    "mmlu_college_biology_g2b": {
      "acc,none": 0.3263888888888889,
      "acc_stderr,none": 0.03921067198982266,
      "alias": " - mmlu_college_biology_g2b"
    },
    "mmlu_college_medicine_b2g": {
      "acc,none": 0.2947976878612717,
      "acc_stderr,none": 0.03476599607516478,
      "alias": " - mmlu_college_medicine_b2g"
    },
    "mmlu_college_medicine_g2b": {
      "acc,none": 0.2947976878612717,
      "acc_stderr,none": 0.03476599607516478,
      "alias": " - mmlu_college_medicine_g2b"
    },
    "mmlu_medical_genetics_b2g": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": " - mmlu_medical_genetics_b2g"
    },
    "mmlu_medical_genetics_g2b": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": " - mmlu_medical_genetics_g2b"
    },
    "mmlu_professional_medicine_b2g": {
      "acc,none": 0.25735294117647056,
      "acc_stderr,none": 0.02655651947004151,
      "alias": " - mmlu_professional_medicine_b2g"
    },
    "mmlu_professional_medicine_g2b": {
      "acc,none": 0.25735294117647056,
      "acc_stderr,none": 0.026556519470041513,
      "alias": " - mmlu_professional_medicine_g2b"
    },
    "pubmedqa": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.019384310743640384,
      "alias": " - pubmedqa"
    },
    "usmle_sa_step1": {
      "acc,none": 0.43617021276595747,
      "acc_stderr,none": 0.05142337009629789,
      "alias": " - usmle_sa_step1"
    },
    "usmle_sa_step1_b2g": {
      "acc,none": 0.43617021276595747,
      "acc_stderr,none": 0.05142337009629788,
      "alias": " - usmle_sa_step1_b2g"
    },
    "usmle_sa_step1_g2b": {
      "acc,none": 0.43617021276595747,
      "acc_stderr,none": 0.051423370096297896,
      "alias": " - usmle_sa_step1_g2b"
    },
    "usmle_sa_step2": {
      "acc,none": 0.5229357798165137,
      "acc_stderr,none": 0.048061876591748334,
      "alias": " - usmle_sa_step2"
    },
    "usmle_sa_step2_b2g": {
      "acc,none": 0.5229357798165137,
      "acc_stderr,none": 0.048061876591748334,
      "alias": " - usmle_sa_step2_b2g"
    },
    "usmle_sa_step2_g2b": {
      "acc,none": 0.5229357798165137,
      "acc_stderr,none": 0.048061876591748334,
      "alias": " - usmle_sa_step2_g2b"
    },
    "usmle_sa_step3": {
      "acc,none": 0.5409836065573771,
      "acc_stderr,none": 0.04530159211198411,
      "alias": " - usmle_sa_step3"
    },
    "usmle_sa_step3_b2g": {
      "acc,none": 0.5409836065573771,
      "acc_stderr,none": 0.04530159211198411,
      "alias": " - usmle_sa_step3_b2g"
    },
    "usmle_sa_step3_g2b": {
      "acc,none": 0.5409836065573771,
      "acc_stderr,none": 0.04530159211198411,
      "alias": " - usmle_sa_step3_g2b"
    }
  },
  "groups": {
    "b4b": {
      "acc,none": 0.46366650876361915,
      "acc_stderr,none": 0.07734244685954582,
      "acc_norm,none": 0.463107485130192,
      "acc_norm_stderr,none": 0.00024675669553543024,
      "alias": "b4b"
    }
  },
  "configs": {
    "b4b_mmlu_anatomy": {
      "task": "b4b_mmlu_anatomy",
      "task_alias": "anatomy (mmlu)",
      "group": "b4b",
      "dataset_path": "hails/mmlu_no_train",
      "dataset_name": "anatomy",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "The following are multiple choice questions (with answers) about anatomy.\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "b4b_mmlu_clinical_knowledge": {
      "task": "b4b_mmlu_clinical_knowledge",
      "task_alias": "clinical_knowledge (mmlu)",
      "group": "b4b",
      "dataset_path": "hails/mmlu_no_train",
      "dataset_name": "clinical_knowledge",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "The following are multiple choice questions (with answers) about clinical knowledge.\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "b4b_mmlu_college_biology": {
      "task": "b4b_mmlu_college_biology",
      "task_alias": "college_biology (mmlu)",
      "group": "b4b",
      "dataset_path": "hails/mmlu_no_train",
      "dataset_name": "college_biology",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "The following are multiple choice questions (with answers) about college biology.\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "b4b_mmlu_college_medicine": {
      "task": "b4b_mmlu_college_medicine",
      "task_alias": "college_medicine (mmlu)",
      "group": "b4b",
      "dataset_path": "hails/mmlu_no_train",
      "dataset_name": "college_medicine",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "The following are multiple choice questions (with answers) about college medicine.\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "b4b_mmlu_medical_genetics": {
      "task": "b4b_mmlu_medical_genetics",
      "task_alias": "medical_genetics (mmlu)",
      "group": "b4b",
      "dataset_path": "hails/mmlu_no_train",
      "dataset_name": "medical_genetics",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "The following are multiple choice questions (with answers) about medical genetics.\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "b4b_mmlu_professional_medicine": {
      "task": "b4b_mmlu_professional_medicine",
      "task_alias": "professional_medicine (mmlu)",
      "group": "b4b",
      "dataset_path": "hails/mmlu_no_train",
      "dataset_name": "professional_medicine",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "The following are multiple choice questions (with answers) about professional medicine.\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "medmcqa": {
      "task": "medmcqa",
      "dataset_path": "medmcqa",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x7fd94da09d30>",
      "doc_to_target": "cop",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "{{question}}"
    },
    "medmcqa_b2g": {
      "task": "medmcqa_b2g",
      "dataset_path": "gallifantjack/medmcqa_brand_to_generic",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x7fd95986aee0>",
      "doc_to_target": "cop",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "{{question}}"
    },
    "medmcqa_g2b": {
      "task": "medmcqa_g2b",
      "dataset_path": "gallifantjack/medmcqa_generic_to_brand",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x7fd959c0d430>",
      "doc_to_target": "cop",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "{{question}}"
    },
    "medqa_4options": {
      "task": "medqa_4options",
      "dataset_path": "GBaker/MedQA-USMLE-4-options-hf",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "<function doc_to_text at 0x7fd957798b80>",
      "doc_to_target": "<function doc_to_target at 0x7fd957798d30>",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false
    },
    "medqa_4options_b2g": {
      "task": "medqa_4options_b2g",
      "dataset_path": "gallifantjack/gbaker_medqa_usmle_4_options_hf_brand_to_generic",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "<function doc_to_text at 0x7fd9576fc8b0>",
      "doc_to_target": "<function doc_to_target at 0x7fd9576fcc10>",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false
    },
    "medqa_4options_g2b": {
      "task": "medqa_4options_g2b",
      "dataset_path": "gallifantjack/gbaker_medqa_usmle_4_options_hf_generic_to_brand",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "<function doc_to_text at 0x7fd959c0dd30>",
      "doc_to_target": "<function doc_to_target at 0x7fd959ded0d0>",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false
    },
    "mmlu_anatomy_b2g": {
      "task": "mmlu_anatomy_b2g",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_anatomy_brand_to_generic",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_anatomy_g2b": {
      "task": "mmlu_anatomy_g2b",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_anatomy_generic_to_brand",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_clinical_knowledge_b2g": {
      "task": "mmlu_clinical_knowledge_b2g",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_clinical_knowledge_brand_to_generic",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_clinical_knowledge_g2b": {
      "task": "mmlu_clinical_knowledge_g2b",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_clinical_knowledge_generic_to_brand",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_college_biology_b2g": {
      "task": "mmlu_college_biology_b2g",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_college_biology_brand_to_generic",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_college_biology_g2b": {
      "task": "mmlu_college_biology_g2b",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_college_biology_generic_to_brand",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_college_medicine_b2g": {
      "task": "mmlu_college_medicine_b2g",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_college_medicine_brand_to_generic",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_college_medicine_g2b": {
      "task": "mmlu_college_medicine_g2b",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_college_medicine_generic_to_brand",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_medical_genetics_b2g": {
      "task": "mmlu_medical_genetics_b2g",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_medical_genetics_brand_to_generic",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_medical_genetics_g2b": {
      "task": "mmlu_medical_genetics_g2b",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_medical_genetics_generic_to_brand",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_professional_medicine_b2g": {
      "task": "mmlu_professional_medicine_b2g",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_professional_medicine_brand_to_generic",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "mmlu_professional_medicine_g2b": {
      "task": "mmlu_professional_medicine_g2b",
      "dataset_path": "gallifantjack/hails_mmlu_no_train_professional_medicine_generic_to_brand",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "pubmedqa": {
      "task": "pubmedqa",
      "dataset_path": "bigbio/pubmed_qa",
      "dataset_name": "pubmed_qa_labeled_fold0_source",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "<function doc_to_text at 0x7fd959ded550>",
      "doc_to_target": "final_decision",
      "doc_to_choice": [
        "yes",
        "no",
        "maybe"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "usmle_sa_step1": {
      "task": "usmle_sa_step1",
      "dataset_path": "augtoma/usmle_step_1",
      "test_split": "test",
      "doc_to_text": "<function process_usmle_sa at 0x7fd959c6b040>",
      "doc_to_target": "answer_idx",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D",
        "E",
        "F",
        "G"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 0.0
        }
      ]
    },
    "usmle_sa_step1_b2g": {
      "task": "usmle_sa_step1_b2g",
      "dataset_path": "gallifantjack/augtoma_usmle_step_1_brand_to_generic",
      "test_split": "test",
      "doc_to_text": "<function process_usmle_sa at 0x7fd94dcac160>",
      "doc_to_target": "answer_idx",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D",
        "E",
        "F",
        "G"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 0.0
        }
      ]
    },
    "usmle_sa_step1_g2b": {
      "task": "usmle_sa_step1_g2b",
      "dataset_path": "gallifantjack/augtoma_usmle_step_1_generic_to_brand",
      "test_split": "test",
      "doc_to_text": "<function process_usmle_sa at 0x7fd94dca6a60>",
      "doc_to_target": "answer_idx",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D",
        "E",
        "F",
        "G"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 0.0
        }
      ]
    },
    "usmle_sa_step2": {
      "task": "usmle_sa_step2",
      "dataset_path": "augtoma/usmle_step_2",
      "test_split": "test",
      "doc_to_text": "<function process_usmle_sa at 0x7fd9576d9a60>",
      "doc_to_target": "answer_idx",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D",
        "E",
        "F",
        "G"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 0.0
        }
      ]
    },
    "usmle_sa_step2_b2g": {
      "task": "usmle_sa_step2_b2g",
      "dataset_path": "gallifantjack/augtoma_usmle_step_2_brand_to_generic",
      "test_split": "test",
      "doc_to_text": "<function process_usmle_sa at 0x7fd94d9de3a0>",
      "doc_to_target": "answer_idx",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D",
        "E",
        "F",
        "G"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 0.0
        }
      ]
    },
    "usmle_sa_step2_g2b": {
      "task": "usmle_sa_step2_g2b",
      "dataset_path": "gallifantjack/augtoma_usmle_step_2_generic_to_brand",
      "test_split": "test",
      "doc_to_text": "<function process_usmle_sa at 0x7fd959c6b310>",
      "doc_to_target": "answer_idx",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D",
        "E",
        "F",
        "G"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 0.0
        }
      ]
    },
    "usmle_sa_step3": {
      "task": "usmle_sa_step3",
      "dataset_path": "augtoma/usmle_step_3",
      "test_split": "test",
      "doc_to_text": "<function process_usmle_sa at 0x7fd9576e9430>",
      "doc_to_target": "answer_idx",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D",
        "E",
        "F",
        "G"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 0.0
        }
      ]
    },
    "usmle_sa_step3_b2g": {
      "task": "usmle_sa_step3_b2g",
      "dataset_path": "gallifantjack/augtoma_usmle_step_3_brand_to_generic",
      "test_split": "test",
      "doc_to_text": "<function process_usmle_sa at 0x7fd94dca6b80>",
      "doc_to_target": "answer_idx",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D",
        "E",
        "F",
        "G"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 0.0
        }
      ]
    },
    "usmle_sa_step3_g2b": {
      "task": "usmle_sa_step3_g2b",
      "dataset_path": "gallifantjack/augtoma_usmle_step_3_generic_to_brand",
      "test_split": "test",
      "doc_to_text": "<function process_usmle_sa at 0x7fd9575bde50>",
      "doc_to_target": "answer_idx",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D",
        "E",
        "F",
        "G"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 0.0
        }
      ]
    }
  },
  "versions": {
    "b4b": "N/A",
    "b4b_mmlu_anatomy": 0.0,
    "b4b_mmlu_clinical_knowledge": 0.0,
    "b4b_mmlu_college_biology": 0.0,
    "b4b_mmlu_college_medicine": 0.0,
    "b4b_mmlu_medical_genetics": 0.0,
    "b4b_mmlu_professional_medicine": 0.0,
    "medmcqa": "Yaml",
    "medmcqa_b2g": "Yaml",
    "medmcqa_g2b": "Yaml",
    "medqa_4options": "Yaml",
    "medqa_4options_b2g": "Yaml",
    "medqa_4options_g2b": "Yaml",
    "mmlu_anatomy_b2g": 0.0,
    "mmlu_anatomy_g2b": 0.0,
    "mmlu_clinical_knowledge_b2g": 0.0,
    "mmlu_clinical_knowledge_g2b": 0.0,
    "mmlu_college_biology_b2g": 0.0,
    "mmlu_college_biology_g2b": 0.0,
    "mmlu_college_medicine_b2g": 0.0,
    "mmlu_college_medicine_g2b": 0.0,
    "mmlu_medical_genetics_b2g": 0.0,
    "mmlu_medical_genetics_g2b": 0.0,
    "mmlu_professional_medicine_b2g": 0.0,
    "mmlu_professional_medicine_g2b": 0.0,
    "pubmedqa": 1.0,
    "usmle_sa_step1": "Yaml",
    "usmle_sa_step1_b2g": "Yaml",
    "usmle_sa_step1_g2b": "Yaml",
    "usmle_sa_step2": "Yaml",
    "usmle_sa_step2_b2g": "Yaml",
    "usmle_sa_step2_g2b": "Yaml",
    "usmle_sa_step3": "Yaml",
    "usmle_sa_step3_b2g": "Yaml",
    "usmle_sa_step3_g2b": "Yaml"
  },
  "n-shot": {
    "b4b": 0,
    "b4b_mmlu_anatomy": 0,
    "b4b_mmlu_clinical_knowledge": 0,
    "b4b_mmlu_college_biology": 0,
    "b4b_mmlu_college_medicine": 0,
    "b4b_mmlu_medical_genetics": 0,
    "b4b_mmlu_professional_medicine": 0,
    "medmcqa": 0,
    "medmcqa_b2g": 0,
    "medmcqa_g2b": 0,
    "medqa_4options": 0,
    "medqa_4options_b2g": 0,
    "medqa_4options_g2b": 0,
    "mmlu_anatomy_b2g": 0,
    "mmlu_anatomy_g2b": 0,
    "mmlu_clinical_knowledge_b2g": 0,
    "mmlu_clinical_knowledge_g2b": 0,
    "mmlu_college_biology_b2g": 0,
    "mmlu_college_biology_g2b": 0,
    "mmlu_college_medicine_b2g": 0,
    "mmlu_college_medicine_g2b": 0,
    "mmlu_medical_genetics_b2g": 0,
    "mmlu_medical_genetics_g2b": 0,
    "mmlu_professional_medicine_b2g": 0,
    "mmlu_professional_medicine_g2b": 0,
    "pubmedqa": 0,
    "usmle_sa_step1": 0,
    "usmle_sa_step1_b2g": 0,
    "usmle_sa_step1_g2b": 0,
    "usmle_sa_step2": 0,
    "usmle_sa_step2_b2g": 0,
    "usmle_sa_step2_g2b": 0,
    "usmle_sa_step3": 0,
    "usmle_sa_step3_b2g": 0,
    "usmle_sa_step3_g2b": 0
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=mistralai/Mistral-7B-v0.1",
    "batch_size": "auto:64",
    "batch_sizes": [
      16,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64,
      64
    ],
    "device": "cuda:0",
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": null
  },
  "git_hash": "b4fcce0f"
}