usage: huggingface-cli <command> [<args>] login [-h] [--token TOKEN]
                                                [--add-to-git-credential]
huggingface-cli <command> [<args>] login: error: argument --token: expected one argument
Running evaluation for model aaditya/Llama3-OpenBioLLM-70B
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2024-06-13:19:58:57,039 INFO     [utils.py:148] Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-06-13:19:58:57,040 INFO     [utils.py:161] NumExpr defaulting to 8 threads.
2024-06-13:19:58:57,513 INFO     [config.py:58] PyTorch version 2.3.0 available.
2024-06-13:19:59:09,514 INFO     [__main__.py:156] Verbosity set to INFO
2024-06-13:19:59:14,779 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-06-13:19:59:40,905 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-06-13:19:59:40,908 INFO     [__main__.py:229] Selected Tasks: ['b4bqa']
2024-06-13:19:59:40,973 WARNING  [other.py:349] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 30/30 [00:00<00:00, 1189.67it/s]
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:11<05:19, 11.03s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:21<04:58, 10.67s/it]Loading checkpoint shards:  10%|█         | 3/30 [00:30<04:29,  9.98s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [00:39<04:06,  9.48s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [00:50<04:09,  9.98s/it]Loading checkpoint shards:  20%|██        | 6/30 [00:58<03:47,  9.49s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [01:07<03:30,  9.14s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [01:17<03:26,  9.39s/it]Loading checkpoint shards:  30%|███       | 9/30 [01:26<03:14,  9.26s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [01:34<02:59,  8.95s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [01:42<02:47,  8.82s/it]Loading checkpoint shards:  40%|████      | 12/30 [01:51<02:36,  8.68s/it]Loading checkpoint shards:  43%|████▎     | 13/30 [02:00<02:28,  8.76s/it]Loading checkpoint shards:  47%|████▋     | 14/30 [02:12<02:36,  9.80s/it]Loading checkpoint shards:  50%|█████     | 15/30 [02:20<02:20,  9.35s/it]Loading checkpoint shards:  53%|█████▎    | 16/30 [02:30<02:11,  9.41s/it]Loading checkpoint shards:  57%|█████▋    | 17/30 [02:41<02:08,  9.87s/it]Loading checkpoint shards:  60%|██████    | 18/30 [02:50<01:58,  9.86s/it]Loading checkpoint shards:  63%|██████▎   | 19/30 [03:01<01:51, 10.17s/it]Loading checkpoint shards:  67%|██████▋   | 20/30 [03:11<01:38,  9.87s/it]Loading checkpoint shards:  70%|███████   | 21/30 [03:20<01:28,  9.86s/it]Loading checkpoint shards:  73%|███████▎  | 22/30 [03:29<01:15,  9.40s/it]Loading checkpoint shards:  77%|███████▋  | 23/30 [03:37<01:04,  9.20s/it]Loading checkpoint shards:  80%|████████  | 24/30 [03:48<00:57,  9.58s/it]Loading checkpoint shards:  83%|████████▎ | 25/30 [03:56<00:45,  9.10s/it]Loading checkpoint shards:  87%|████████▋ | 26/30 [04:06<00:37,  9.44s/it]Loading checkpoint shards:  90%|█████████ | 27/30 [04:14<00:27,  9.03s/it]Loading checkpoint shards:  93%|█████████▎| 28/30 [04:23<00:18,  9.03s/it]Loading checkpoint shards:  97%|█████████▋| 29/30 [04:33<00:09,  9.41s/it]Loading checkpoint shards: 100%|██████████| 30/30 [04:37<00:00,  7.79s/it]Loading checkpoint shards: 100%|██████████| 30/30 [04:37<00:00,  9.27s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Downloading readme:   0%|          | 0.00/31.0 [00:00<?, ?B/s]Downloading readme: 100%|██████████| 31.0/31.0 [00:00<00:00, 154kB/s]
Downloading data:   0%|          | 0.00/160k [00:00<?, ?B/s]Downloading data: 100%|██████████| 160k/160k [00:00<00:00, 2.46MB/s]
Generating test split:   0%|          | 0/1048 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 1048/1048 [00:00<00:00, 2789.59 examples/s]Generating test split: 100%|██████████| 1048/1048 [00:00<00:00, 2761.65 examples/s]
2024-06-13:20:04:23,636 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:20:04:23,637 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:20:04:23,673 INFO     [task.py:343] Building contexts for task on rank 0...
2024-06-13:20:04:23,740 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/4192 [00:00<?, ?it/s]  0%|          | 1/4192 [00:28<32:45:06, 28.13s/it]  2%|▏         | 65/4192 [00:32<25:40,  2.68it/s]    3%|▎         | 129/4192 [00:37<13:13,  5.12it/s]  5%|▍         | 193/4192 [00:41<09:11,  7.25it/s]  6%|▌         | 257/4192 [00:45<07:13,  9.09it/s]  8%|▊         | 321/4192 [00:50<06:06, 10.56it/s]  9%|▉         | 385/4192 [00:54<05:25, 11.70it/s] 11%|█         | 449/4192 [00:58<04:57, 12.57it/s] 12%|█▏        | 513/4192 [01:03<04:38, 13.22it/s] 14%|█▍        | 577/4192 [01:07<04:23, 13.71it/s] 15%|█▌        | 641/4192 [01:11<04:13, 14.03it/s] 17%|█▋        | 705/4192 [01:15<04:04, 14.28it/s] 18%|█▊        | 769/4192 [01:20<03:56, 14.45it/s] 20%|█▉        | 833/4192 [01:24<03:50, 14.56it/s] 21%|██▏       | 897/4192 [01:28<03:42, 14.79it/s] 23%|██▎       | 961/4192 [01:32<03:36, 14.95it/s] 24%|██▍       | 1025/4192 [01:37<03:30, 15.07it/s] 26%|██▌       | 1089/4192 [01:41<03:24, 15.14it/s] 28%|██▊       | 1153/4192 [01:45<03:20, 15.19it/s] 29%|██▉       | 1217/4192 [01:49<03:15, 15.22it/s] 31%|███       | 1281/4192 [01:53<03:11, 15.24it/s] 32%|███▏      | 1345/4192 [01:57<03:06, 15.25it/s] 34%|███▎      | 1409/4192 [02:02<03:02, 15.26it/s] 35%|███▌      | 1473/4192 [02:06<02:57, 15.30it/s] 37%|███▋      | 1537/4192 [02:10<02:53, 15.31it/s] 38%|███▊      | 1601/4192 [02:14<02:49, 15.32it/s] 40%|███▉      | 1665/4192 [02:18<02:44, 15.33it/s] 41%|████      | 1729/4192 [02:23<02:40, 15.30it/s] 43%|████▎     | 1793/4192 [02:27<02:36, 15.33it/s] 44%|████▍     | 1857/4192 [02:31<02:32, 15.34it/s] 46%|████▌     | 1921/4192 [02:35<02:27, 15.36it/s] 47%|████▋     | 1985/4192 [02:39<02:23, 15.36it/s] 49%|████▉     | 2049/4192 [02:43<02:16, 15.66it/s] 50%|█████     | 2113/4192 [02:47<02:10, 15.88it/s] 52%|█████▏    | 2177/4192 [02:51<02:05, 16.04it/s] 53%|█████▎    | 2241/4192 [02:55<02:00, 16.15it/s] 55%|█████▍    | 2305/4192 [02:59<01:56, 16.24it/s] 57%|█████▋    | 2369/4192 [03:03<01:51, 16.30it/s] 58%|█████▊    | 2433/4192 [03:06<01:47, 16.35it/s] 60%|█████▉    | 2497/4192 [03:10<01:43, 16.38it/s] 61%|██████    | 2561/4192 [03:14<01:39, 16.40it/s] 63%|██████▎   | 2625/4192 [03:18<01:35, 16.42it/s] 64%|██████▍   | 2689/4192 [03:22<01:31, 16.43it/s] 66%|██████▌   | 2753/4192 [03:26<01:27, 16.46it/s] 67%|██████▋   | 2817/4192 [03:30<01:23, 16.49it/s] 69%|██████▊   | 2881/4192 [03:34<01:19, 16.51it/s] 70%|███████   | 2945/4192 [03:37<01:15, 16.54it/s] 72%|███████▏  | 3009/4192 [03:41<01:11, 16.55it/s] 73%|███████▎  | 3073/4192 [03:45<01:07, 16.56it/s] 75%|███████▍  | 3137/4192 [03:49<01:03, 16.57it/s] 76%|███████▋  | 3201/4192 [03:53<00:59, 16.57it/s] 78%|███████▊  | 3265/4192 [03:57<00:55, 16.57it/s] 79%|███████▉  | 3329/4192 [04:01<00:52, 16.57it/s] 81%|████████  | 3393/4192 [04:05<00:48, 16.57it/s] 82%|████████▏ | 3457/4192 [04:08<00:43, 16.71it/s] 84%|████████▍ | 3521/4192 [04:12<00:39, 16.81it/s] 86%|████████▌ | 3585/4192 [04:16<00:35, 16.88it/s] 87%|████████▋ | 3649/4192 [04:20<00:32, 16.94it/s] 89%|████████▊ | 3713/4192 [04:23<00:28, 16.98it/s] 90%|█████████ | 3777/4192 [04:27<00:24, 17.01it/s] 92%|█████████▏| 3841/4192 [04:31<00:20, 17.02it/s] 93%|█████████▎| 3905/4192 [04:34<00:16, 17.06it/s] 95%|█████████▍| 3969/4192 [04:38<00:13, 17.09it/s] 96%|█████████▌| 4033/4192 [04:42<00:09, 17.10it/s] 98%|█████████▊| 4097/4192 [04:46<00:05, 17.23it/s] 99%|█████████▉| 4161/4192 [04:48<00:01, 19.88it/s]100%|██████████| 4192/4192 [04:48<00:00, 14.55it/s]
Passed argument batch_size = auto:1. Detecting largest batch size
Determined largest batch size: 64
hf (pretrained=aaditya/Llama3-OpenBioLLM-70B,parallelize=True,load_in_4bit=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)
|Tasks|Version|Filter|n-shot| Metric |Value |   |Stderr|
|-----|-------|------|-----:|--------|-----:|---|-----:|
|b4bqa|Yaml   |none  |     0|acc     |0.9742|±  |0.0049|
|     |       |none  |     0|acc_norm|0.9742|±  |0.0049|

Running evaluation for model ProbeMedicalYonseiMAILab/medllama3-v20
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2024-06-13:20:09:25,019 INFO     [utils.py:148] Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-06-13:20:09:25,019 INFO     [utils.py:161] NumExpr defaulting to 8 threads.
2024-06-13:20:09:25,477 INFO     [config.py:58] PyTorch version 2.3.0 available.
2024-06-13:20:09:37,437 INFO     [__main__.py:156] Verbosity set to INFO
2024-06-13:20:09:42,569 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-06-13:20:10:08,546 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-06-13:20:10:08,548 INFO     [__main__.py:229] Selected Tasks: ['b4bqa']
2024-06-13:20:10:08,617 WARNING  [other.py:349] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:  75%|███████▌  | 3/4 [00:00<00:00, 21.65it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 21.84it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [01:32<04:37, 92.53s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:56<01:44, 52.07s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:16<00:37, 37.60s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:22<00:00, 25.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:22<00:00, 35.59s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-06-13:20:12:36,311 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:20:12:36,312 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:20:12:36,345 INFO     [task.py:343] Building contexts for task on rank 0...
2024-06-13:20:12:36,410 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/4192 [00:00<?, ?it/s]  0%|          | 1/4192 [00:05<6:40:33,  5.73s/it]  2%|▏         | 65/4192 [00:06<05:09, 13.33it/s]   3%|▎         | 129/4192 [00:07<02:37, 25.86it/s]  5%|▍         | 193/4192 [00:08<01:47, 37.10it/s]  6%|▌         | 257/4192 [00:09<01:23, 47.00it/s]  8%|▊         | 321/4192 [00:09<01:10, 55.14it/s]  9%|▉         | 385/4192 [00:10<01:01, 61.58it/s] 11%|█         | 449/4192 [00:11<00:56, 66.52it/s] 12%|█▏        | 513/4192 [00:12<00:52, 70.46it/s] 14%|█▍        | 577/4192 [00:13<00:49, 73.37it/s] 15%|█▌        | 641/4192 [00:13<00:47, 75.48it/s] 17%|█▋        | 705/4192 [00:14<00:45, 77.00it/s] 18%|█▊        | 769/4192 [00:15<00:43, 78.06it/s] 20%|█▉        | 833/4192 [00:16<00:42, 78.79it/s] 21%|██▏       | 897/4192 [00:16<00:41, 79.88it/s] 23%|██▎       | 961/4192 [00:17<00:40, 80.67it/s] 24%|██▍       | 1025/4192 [00:18<00:38, 81.21it/s] 26%|██▌       | 1089/4192 [00:19<00:38, 81.58it/s] 28%|██▊       | 1153/4192 [00:20<00:37, 81.85it/s] 29%|██▉       | 1217/4192 [00:20<00:36, 82.02it/s] 31%|███       | 1281/4192 [00:21<00:35, 82.16it/s] 32%|███▏      | 1345/4192 [00:22<00:34, 82.22it/s] 34%|███▎      | 1409/4192 [00:23<00:33, 82.25it/s] 35%|███▌      | 1473/4192 [00:23<00:32, 82.60it/s] 37%|███▋      | 1537/4192 [00:24<00:32, 82.86it/s] 38%|███▊      | 1601/4192 [00:25<00:31, 83.08it/s] 40%|███▉      | 1665/4192 [00:26<00:30, 83.22it/s] 41%|████      | 1729/4192 [00:27<00:29, 83.32it/s] 43%|████▎     | 1793/4192 [00:27<00:28, 83.40it/s] 44%|████▍     | 1857/4192 [00:28<00:27, 83.47it/s] 46%|████▌     | 1921/4192 [00:29<00:27, 83.49it/s] 47%|████▋     | 1985/4192 [00:30<00:26, 83.50it/s] 49%|████▉     | 2049/4192 [00:30<00:25, 84.80it/s] 50%|█████     | 2113/4192 [00:31<00:24, 85.70it/s] 52%|█████▏    | 2177/4192 [00:32<00:23, 86.37it/s] 53%|█████▎    | 2241/4192 [00:32<00:22, 86.82it/s] 55%|█████▍    | 2305/4192 [00:33<00:21, 87.13it/s] 57%|█████▋    | 2369/4192 [00:34<00:20, 87.35it/s] 58%|█████▊    | 2433/4192 [00:35<00:20, 87.52it/s] 60%|█████▉    | 2497/4192 [00:35<00:19, 87.65it/s] 61%|██████    | 2561/4192 [00:36<00:18, 87.71it/s] 63%|██████▎   | 2625/4192 [00:37<00:17, 87.78it/s] 64%|██████▍   | 2689/4192 [00:38<00:17, 87.81it/s] 66%|██████▌   | 2753/4192 [00:38<00:16, 88.12it/s] 67%|██████▋   | 2817/4192 [00:39<00:15, 88.31it/s] 69%|██████▊   | 2881/4192 [00:40<00:14, 88.49it/s] 70%|███████   | 2945/4192 [00:40<00:14, 88.63it/s] 72%|███████▏  | 3009/4192 [00:41<00:13, 88.68it/s] 73%|███████▎  | 3073/4192 [00:42<00:12, 88.73it/s] 75%|███████▍  | 3137/4192 [00:43<00:11, 88.77it/s] 76%|███████▋  | 3201/4192 [00:43<00:11, 88.79it/s] 78%|███████▊  | 3265/4192 [00:44<00:10, 88.81it/s] 79%|███████▉  | 3329/4192 [00:45<00:09, 88.82it/s] 81%|████████  | 3393/4192 [00:46<00:08, 88.82it/s] 82%|████████▏ | 3457/4192 [00:46<00:08, 89.31it/s] 84%|████████▍ | 3521/4192 [00:47<00:07, 89.68it/s] 86%|████████▌ | 3585/4192 [00:48<00:06, 89.92it/s] 87%|████████▋ | 3649/4192 [00:48<00:06, 90.05it/s] 89%|████████▊ | 3713/4192 [00:49<00:05, 90.18it/s] 90%|█████████ | 3777/4192 [00:50<00:04, 90.27it/s] 92%|█████████▏| 3841/4192 [00:50<00:03, 90.28it/s] 93%|█████████▎| 3905/4192 [00:51<00:03, 90.70it/s] 95%|█████████▍| 3969/4192 [00:52<00:02, 91.02it/s] 96%|█████████▌| 4033/4192 [00:53<00:01, 91.21it/s] 98%|█████████▊| 4097/4192 [00:53<00:01, 92.09it/s] 99%|█████████▉| 4161/4192 [00:54<00:00, 107.18it/s]100%|██████████| 4192/4192 [00:54<00:00, 77.46it/s] 
Passed argument batch_size = auto:1. Detecting largest batch size
Determined largest batch size: 64
hf (pretrained=ProbeMedicalYonseiMAILab/medllama3-v20,parallelize=True,load_in_4bit=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)
|Tasks|Version|Filter|n-shot| Metric |Value |   |Stderr|
|-----|-------|------|-----:|--------|-----:|---|-----:|
|b4bqa|Yaml   |none  |     0|acc     |0.9246|±  |0.0082|
|     |       |none  |     0|acc_norm|0.9246|±  |0.0082|

Running evaluation for model johnsnowlabs/JSL-MedLlama-3-8B-v9
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2024-06-13:20:13:37,851 INFO     [utils.py:148] Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-06-13:20:13:37,851 INFO     [utils.py:161] NumExpr defaulting to 8 threads.
2024-06-13:20:13:38,088 INFO     [config.py:58] PyTorch version 2.3.0 available.
2024-06-13:20:13:47,735 INFO     [__main__.py:156] Verbosity set to INFO
2024-06-13:20:13:52,611 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-06-13:20:14:18,651 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-06-13:20:14:18,653 INFO     [__main__.py:229] Selected Tasks: ['b4bqa']
2024-06-13:20:14:18,713 WARNING  [other.py:349] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 369.19it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [01:26<04:18, 86.14s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:47<01:35, 47.74s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:02<01:00, 60.43s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:09<00:00, 39.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:09<00:00, 47.28s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-06-13:20:17:30,795 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:20:17:30,795 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:20:17:30,827 INFO     [task.py:343] Building contexts for task on rank 0...
2024-06-13:20:17:30,892 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/4192 [00:00<?, ?it/s]  0%|          | 1/4192 [00:04<5:37:54,  4.84s/it]  2%|▏         | 65/4192 [00:05<04:12, 16.35it/s]   3%|▎         | 129/4192 [00:05<02:03, 32.77it/s]  5%|▍         | 193/4192 [00:06<01:22, 48.41it/s]  6%|▌         | 257/4192 [00:07<01:02, 62.92it/s]  8%|▊         | 321/4192 [00:07<00:51, 75.41it/s]  9%|▉         | 385/4192 [00:08<00:44, 85.71it/s] 11%|█         | 449/4192 [00:08<00:39, 93.85it/s] 12%|█▏        | 513/4192 [00:09<00:36, 100.19it/s] 14%|█▍        | 577/4192 [00:09<00:34, 104.95it/s] 15%|█▌        | 641/4192 [00:10<00:32, 108.50it/s] 17%|█▋        | 705/4192 [00:10<00:31, 110.99it/s] 18%|█▊        | 769/4192 [00:11<00:30, 112.83it/s] 20%|█▉        | 833/4192 [00:12<00:29, 114.14it/s] 21%|██▏       | 897/4192 [00:12<00:28, 116.00it/s] 23%|██▎       | 961/4192 [00:13<00:27, 117.36it/s] 24%|██▍       | 1025/4192 [00:13<00:26, 118.33it/s] 26%|██▌       | 1089/4192 [00:14<00:26, 119.01it/s] 28%|██▊       | 1153/4192 [00:14<00:25, 119.42it/s] 29%|██▉       | 1217/4192 [00:15<00:24, 119.74it/s] 31%|███       | 1281/4192 [00:15<00:24, 120.06it/s] 32%|███▏      | 1345/4192 [00:16<00:23, 120.31it/s] 34%|███▎      | 1409/4192 [00:16<00:23, 120.18it/s] 35%|███▌      | 1473/4192 [00:17<00:22, 120.57it/s] 37%|███▋      | 1537/4192 [00:17<00:21, 120.88it/s] 38%|███▊      | 1601/4192 [00:18<00:21, 121.06it/s] 40%|███▉      | 1665/4192 [00:18<00:20, 121.21it/s] 41%|████      | 1729/4192 [00:19<00:20, 121.28it/s] 43%|████▎     | 1793/4192 [00:19<00:19, 121.34it/s] 44%|████▍     | 1857/4192 [00:20<00:19, 121.42it/s] 46%|████▌     | 1921/4192 [00:21<00:18, 121.33it/s] 47%|████▋     | 1985/4192 [00:21<00:18, 121.29it/s] 49%|████▉     | 2049/4192 [00:22<00:17, 123.52it/s] 50%|█████     | 2113/4192 [00:22<00:16, 125.27it/s] 52%|█████▏    | 2177/4192 [00:23<00:15, 126.39it/s] 53%|█████▎    | 2241/4192 [00:23<00:15, 127.27it/s] 55%|█████▍    | 2305/4192 [00:24<00:14, 127.85it/s] 57%|█████▋    | 2369/4192 [00:24<00:14, 128.41it/s] 58%|█████▊    | 2433/4192 [00:24<00:13, 128.80it/s] 60%|█████▉    | 2497/4192 [00:25<00:13, 128.88it/s] 61%|██████    | 2561/4192 [00:25<00:12, 129.07it/s] 63%|██████▎   | 2625/4192 [00:26<00:12, 129.20it/s] 64%|██████▍   | 2689/4192 [00:26<00:11, 129.11it/s] 66%|██████▌   | 2753/4192 [00:27<00:11, 129.43it/s] 67%|██████▋   | 2817/4192 [00:27<00:10, 129.77it/s] 69%|██████▊   | 2881/4192 [00:28<00:10, 130.02it/s] 70%|███████   | 2945/4192 [00:28<00:09, 130.11it/s] 72%|███████▏  | 3009/4192 [00:29<00:09, 130.21it/s] 73%|███████▎  | 3073/4192 [00:29<00:08, 130.25it/s] 75%|███████▍  | 3137/4192 [00:30<00:08, 130.34it/s] 76%|███████▋  | 3201/4192 [00:30<00:07, 130.40it/s] 78%|███████▊  | 3265/4192 [00:31<00:07, 130.41it/s] 79%|███████▉  | 3329/4192 [00:31<00:06, 130.40it/s] 81%|████████  | 3393/4192 [00:32<00:06, 130.45it/s] 82%|████████▏ | 3457/4192 [00:32<00:05, 130.94it/s] 84%|████████▍ | 3521/4192 [00:33<00:05, 131.24it/s] 86%|████████▌ | 3585/4192 [00:33<00:04, 131.42it/s] 87%|████████▋ | 3649/4192 [00:34<00:04, 131.62it/s] 89%|████████▊ | 3713/4192 [00:34<00:03, 131.82it/s] 90%|█████████ | 3777/4192 [00:35<00:03, 131.88it/s] 92%|█████████▏| 3841/4192 [00:35<00:02, 131.88it/s] 93%|█████████▎| 3905/4192 [00:36<00:02, 132.19it/s] 95%|█████████▍| 3969/4192 [00:36<00:01, 132.41it/s] 96%|█████████▌| 4033/4192 [00:37<00:01, 132.55it/s] 98%|█████████▊| 4097/4192 [00:37<00:00, 133.96it/s] 99%|█████████▉| 4161/4192 [00:37<00:00, 155.17it/s]100%|██████████| 4192/4192 [00:37<00:00, 110.48it/s]
Passed argument batch_size = auto:1. Detecting largest batch size
Determined largest batch size: 64
hf (pretrained=johnsnowlabs/JSL-MedLlama-3-8B-v9,parallelize=True,load_in_4bit=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)
|Tasks|Version|Filter|n-shot| Metric |Value |   |Stderr|
|-----|-------|------|-----:|--------|-----:|---|-----:|
|b4bqa|Yaml   |none  |     0|acc     |0.9342|±  |0.0077|
|     |       |none  |     0|acc_norm|0.9342|±  |0.0077|

Running evaluation for model 01-ai/Yi-1.5-34B
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2024-06-13:20:18:16,033 INFO     [utils.py:148] Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-06-13:20:18:16,033 INFO     [utils.py:161] NumExpr defaulting to 8 threads.
2024-06-13:20:18:16,271 INFO     [config.py:58] PyTorch version 2.3.0 available.
2024-06-13:20:18:25,876 INFO     [__main__.py:156] Verbosity set to INFO
2024-06-13:20:18:30,717 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-06-13:20:18:56,315 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-06-13:20:18:56,317 INFO     [__main__.py:229] Selected Tasks: ['b4bqa']
2024-06-13:20:18:56,378 WARNING  [other.py:349] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Downloading shards:   0%|          | 0/15 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 15/15 [00:00<00:00, 330.33it/s]
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:17<04:06, 17.62s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:36<03:58, 18.34s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:54<03:38, 18.17s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [01:11<03:14, 17.68s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [01:29<02:57, 17.78s/it]Loading checkpoint shards:  40%|████      | 6/15 [01:47<02:40, 17.78s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [02:06<02:26, 18.25s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [02:22<02:04, 17.72s/it]Loading checkpoint shards:  60%|██████    | 9/15 [02:41<01:48, 18.11s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [02:58<01:27, 17.50s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [03:16<01:11, 17.83s/it]Loading checkpoint shards:  80%|████████  | 12/15 [03:34<00:53, 17.94s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [03:52<00:35, 17.73s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [04:10<00:17, 17.89s/it]Loading checkpoint shards: 100%|██████████| 15/15 [04:15<00:00, 14.09s/it]Loading checkpoint shards: 100%|██████████| 15/15 [04:15<00:00, 17.04s/it]
2024-06-13:20:23:15,153 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:20:23:15,154 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:20:23:15,188 INFO     [task.py:343] Building contexts for task on rank 0...
2024-06-13:20:23:15,253 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/4192 [00:00<?, ?it/s]  0%|          | 1/4192 [00:15<17:39:44, 15.17s/it]  2%|▏         | 65/4192 [00:17<13:46,  5.00it/s]    3%|▎         | 129/4192 [00:19<07:03,  9.59it/s]  5%|▍         | 193/4192 [00:22<04:52, 13.65it/s]  6%|▌         | 257/4192 [00:24<03:50, 17.05it/s]  8%|▊         | 321/4192 [00:26<03:15, 19.77it/s]  9%|▉         | 385/4192 [00:28<02:51, 22.19it/s] 11%|█         | 449/4192 [00:31<02:35, 24.05it/s] 12%|█▏        | 513/4192 [00:33<02:24, 25.46it/s] 14%|█▍        | 577/4192 [00:35<02:16, 26.49it/s] 15%|█▌        | 641/4192 [00:37<02:10, 27.24it/s] 17%|█▋        | 705/4192 [00:39<02:05, 27.77it/s] 18%|█▊        | 769/4192 [00:42<02:01, 28.19it/s] 20%|█▉        | 833/4192 [00:44<01:57, 28.49it/s] 21%|██▏       | 897/4192 [00:46<01:54, 28.70it/s] 23%|██▎       | 961/4192 [00:48<01:52, 28.84it/s] 24%|██▍       | 1025/4192 [00:50<01:49, 28.94it/s] 26%|██▌       | 1089/4192 [00:53<01:46, 29.02it/s] 28%|██▊       | 1153/4192 [00:55<01:44, 29.08it/s] 29%|██▉       | 1217/4192 [00:57<01:41, 29.30it/s] 31%|███       | 1281/4192 [00:59<01:38, 29.45it/s] 32%|███▏      | 1345/4192 [01:01<01:36, 29.57it/s] 34%|███▎      | 1409/4192 [01:03<01:33, 29.63it/s] 35%|███▌      | 1473/4192 [01:06<01:31, 29.67it/s] 37%|███▋      | 1537/4192 [01:08<01:29, 29.70it/s] 38%|███▊      | 1601/4192 [01:10<01:27, 29.72it/s] 40%|███▉      | 1665/4192 [01:12<01:24, 29.75it/s] 41%|████      | 1729/4192 [01:14<01:22, 29.77it/s] 43%|████▎     | 1793/4192 [01:16<01:20, 29.77it/s] 44%|████▍     | 1857/4192 [01:18<01:18, 29.81it/s] 46%|████▌     | 1921/4192 [01:21<01:16, 29.85it/s] 47%|████▋     | 1985/4192 [01:23<01:13, 29.86it/s] 49%|████▉     | 2049/4192 [01:25<01:11, 29.87it/s] 50%|█████     | 2113/4192 [01:27<01:09, 29.87it/s] 52%|█████▏    | 2177/4192 [01:29<01:07, 29.87it/s] 53%|█████▎    | 2241/4192 [01:31<01:05, 29.85it/s] 55%|█████▍    | 2305/4192 [01:33<01:03, 29.85it/s] 57%|█████▋    | 2369/4192 [01:36<01:01, 29.86it/s] 58%|█████▊    | 2433/4192 [01:38<00:58, 30.10it/s] 60%|█████▉    | 2497/4192 [01:40<00:55, 30.29it/s] 61%|██████    | 2561/4192 [01:42<00:53, 30.41it/s] 63%|██████▎   | 2625/4192 [01:44<00:51, 30.49it/s] 64%|██████▍   | 2689/4192 [01:46<00:49, 30.55it/s] 66%|██████▌   | 2753/4192 [01:48<00:47, 30.59it/s] 67%|██████▋   | 2817/4192 [01:50<00:44, 30.61it/s] 69%|██████▊   | 2881/4192 [01:52<00:42, 30.62it/s] 70%|███████   | 2945/4192 [01:54<00:40, 30.64it/s] 72%|███████▏  | 3009/4192 [01:56<00:38, 30.64it/s] 73%|███████▎  | 3073/4192 [01:59<00:36, 30.69it/s] 75%|███████▍  | 3137/4192 [02:01<00:34, 30.72it/s] 76%|███████▋  | 3201/4192 [02:03<00:32, 30.74it/s] 78%|███████▊  | 3265/4192 [02:05<00:30, 30.76it/s] 79%|███████▉  | 3329/4192 [02:07<00:28, 30.78it/s] 81%|████████  | 3393/4192 [02:09<00:25, 30.78it/s] 82%|████████▏ | 3457/4192 [02:11<00:23, 30.79it/s] 84%|████████▍ | 3521/4192 [02:13<00:21, 30.79it/s] 86%|████████▌ | 3585/4192 [02:15<00:19, 30.80it/s] 87%|████████▋ | 3649/4192 [02:17<00:17, 31.36it/s] 89%|████████▊ | 3713/4192 [02:19<00:15, 31.77it/s] 90%|█████████ | 3777/4192 [02:21<00:12, 32.05it/s] 92%|█████████▏| 3841/4192 [02:23<00:10, 32.25it/s] 93%|█████████▎| 3905/4192 [02:25<00:08, 32.39it/s] 95%|█████████▍| 3969/4192 [02:27<00:06, 32.49it/s] 96%|█████████▌| 4033/4192 [02:29<00:04, 32.62it/s] 98%|█████████▊| 4097/4192 [02:31<00:02, 32.82it/s] 99%|█████████▉| 4161/4192 [02:32<00:00, 38.05it/s]100%|██████████| 4192/4192 [02:32<00:00, 27.52it/s]
Passed argument batch_size = auto:1. Detecting largest batch size
Determined largest batch size: 64
hf (pretrained=01-ai/Yi-1.5-34B,parallelize=True,load_in_4bit=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)
|Tasks|Version|Filter|n-shot| Metric |Value |   |Stderr|
|-----|-------|------|-----:|--------|-----:|---|-----:|
|b4bqa|Yaml   |none  |     0|acc     |0.9781|±  |0.0045|
|     |       |none  |     0|acc_norm|0.9781|±  |0.0045|

Running evaluation for model mistralai/Mixtral-8x22B-v0.1
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2024-06-13:20:25:55,000 INFO     [utils.py:148] Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-06-13:20:25:55,000 INFO     [utils.py:161] NumExpr defaulting to 8 threads.
2024-06-13:20:25:55,234 INFO     [config.py:58] PyTorch version 2.3.0 available.
2024-06-13:20:26:04,876 INFO     [__main__.py:156] Verbosity set to INFO
2024-06-13:20:26:09,534 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-06-13:20:26:35,840 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-06-13:20:26:35,842 INFO     [__main__.py:229] Selected Tasks: ['b4bqa']
2024-06-13:20:26:35,902 WARNING  [other.py:349] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Downloading shards:   0%|          | 0/59 [00:00<?, ?it/s]Downloading shards:  51%|█████     | 30/59 [00:00<00:00, 290.99it/s]Downloading shards: 100%|██████████| 59/59 [00:00<00:00, 298.51it/s]
Loading checkpoint shards:   0%|          | 0/59 [00:00<?, ?it/s]Loading checkpoint shards:   2%|▏         | 1/59 [00:16<16:07, 16.68s/it]Loading checkpoint shards:   3%|▎         | 2/59 [00:33<15:54, 16.74s/it]Loading checkpoint shards:   5%|▌         | 3/59 [00:52<16:29, 17.66s/it]Loading checkpoint shards:   7%|▋         | 4/59 [01:09<15:52, 17.31s/it]Loading checkpoint shards:   8%|▊         | 5/59 [01:27<15:50, 17.61s/it]Loading checkpoint shards:  10%|█         | 6/59 [01:44<15:31, 17.58s/it]Loading checkpoint shards:  12%|█▏        | 7/59 [02:02<15:12, 17.54s/it]Loading checkpoint shards:  14%|█▎        | 8/59 [02:20<15:02, 17.70s/it]Loading checkpoint shards:  15%|█▌        | 9/59 [02:40<15:27, 18.55s/it]Loading checkpoint shards:  17%|█▋        | 10/59 [02:58<15:03, 18.45s/it]Loading checkpoint shards:  19%|█▊        | 11/59 [03:13<13:56, 17.43s/it]Loading checkpoint shards:  20%|██        | 12/59 [03:31<13:44, 17.55s/it]Loading checkpoint shards:  22%|██▏       | 13/59 [03:49<13:30, 17.63s/it]Loading checkpoint shards:  24%|██▎       | 14/59 [04:07<13:19, 17.78s/it]Loading checkpoint shards:  25%|██▌       | 15/59 [04:24<12:50, 17.50s/it]Loading checkpoint shards:  27%|██▋       | 16/59 [04:42<12:32, 17.50s/it]Loading checkpoint shards:  29%|██▉       | 17/59 [04:58<12:03, 17.23s/it]Loading checkpoint shards:  31%|███       | 18/59 [05:16<11:53, 17.41s/it]Loading checkpoint shards:  32%|███▏      | 19/59 [05:35<11:52, 17.82s/it]Loading checkpoint shards:  34%|███▍      | 20/59 [07:08<26:21, 40.56s/it]Loading checkpoint shards:  36%|███▌      | 21/59 [07:26<21:20, 33.71s/it]Loading checkpoint shards:  37%|███▋      | 22/59 [07:44<17:57, 29.13s/it]Loading checkpoint shards:  39%|███▉      | 23/59 [08:02<15:23, 25.66s/it]Loading checkpoint shards:  41%|████      | 24/59 [09:57<30:41, 52.60s/it]Loading checkpoint shards:  42%|████▏     | 25/59 [10:16<24:01, 42.40s/it]Loading checkpoint shards:  44%|████▍     | 26/59 [10:32<18:59, 34.52s/it]Loading checkpoint shards:  46%|████▌     | 27/59 [10:47<15:16, 28.64s/it]Loading checkpoint shards:  47%|████▋     | 28/59 [11:04<12:56, 25.03s/it]Loading checkpoint shards:  49%|████▉     | 29/59 [11:21<11:22, 22.73s/it]Loading checkpoint shards:  51%|█████     | 30/59 [11:37<10:03, 20.79s/it]Loading checkpoint shards:  53%|█████▎    | 31/59 [11:54<09:05, 19.47s/it]Loading checkpoint shards:  54%|█████▍    | 32/59 [12:11<08:24, 18.67s/it]Loading checkpoint shards:  56%|█████▌    | 33/59 [12:27<07:50, 18.10s/it]Loading checkpoint shards:  58%|█████▊    | 34/59 [12:44<07:21, 17.66s/it]Loading checkpoint shards:  59%|█████▉    | 35/59 [13:01<06:59, 17.47s/it]Loading checkpoint shards:  61%|██████    | 36/59 [13:19<06:47, 17.72s/it]Loading checkpoint shards:  63%|██████▎   | 37/59 [13:37<06:26, 17.57s/it]Loading checkpoint shards:  64%|██████▍   | 38/59 [13:52<05:55, 16.91s/it]Loading checkpoint shards:  66%|██████▌   | 39/59 [14:09<05:40, 17.02s/it]Loading checkpoint shards:  68%|██████▊   | 40/59 [14:26<05:22, 16.98s/it]Loading checkpoint shards:  69%|██████▉   | 41/59 [14:44<05:08, 17.15s/it]Loading checkpoint shards:  71%|███████   | 42/59 [15:01<04:50, 17.07s/it]Loading checkpoint shards:  73%|███████▎  | 43/59 [15:55<07:31, 28.19s/it]Loading checkpoint shards:  75%|███████▍  | 44/59 [16:12<06:12, 24.83s/it]Loading checkpoint shards:  76%|███████▋  | 45/59 [16:28<05:13, 22.40s/it]Loading checkpoint shards:  78%|███████▊  | 46/59 [16:46<04:32, 20.94s/it]Loading checkpoint shards:  80%|███████▉  | 47/59 [17:01<03:50, 19.20s/it]Loading checkpoint shards:  81%|████████▏ | 48/59 [17:19<03:25, 18.69s/it]Loading checkpoint shards:  83%|████████▎ | 49/59 [17:37<03:06, 18.66s/it]Loading checkpoint shards:  85%|████████▍ | 50/59 [17:54<02:42, 18.03s/it]Loading checkpoint shards:  86%|████████▋ | 51/59 [18:11<02:21, 17.67s/it]Loading checkpoint shards:  88%|████████▊ | 52/59 [18:27<02:00, 17.23s/it]Loading checkpoint shards:  90%|████████▉ | 53/59 [18:42<01:39, 16.56s/it]Loading checkpoint shards:  92%|█████████▏| 54/59 [18:58<01:22, 16.50s/it]Loading checkpoint shards:  93%|█████████▎| 55/59 [19:15<01:06, 16.65s/it]Loading checkpoint shards:  95%|█████████▍| 56/59 [19:36<00:53, 17.98s/it]Loading checkpoint shards:  97%|█████████▋| 57/59 [19:53<00:35, 17.76s/it]Loading checkpoint shards:  98%|█████████▊| 58/59 [20:10<00:17, 17.32s/it]Loading checkpoint shards: 100%|██████████| 59/59 [20:14<00:00, 13.32s/it]Loading checkpoint shards: 100%|██████████| 59/59 [20:14<00:00, 20.58s/it]
2024-06-13:20:47:05,647 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:20:47:05,648 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:20:47:05,679 INFO     [task.py:343] Building contexts for task on rank 0...
2024-06-13:20:47:05,746 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/4192 [00:00<?, ?it/s]  0%|          | 1/4192 [00:21<24:30:57, 21.06s/it]  2%|▏         | 65/4192 [00:24<19:28,  3.53it/s]    3%|▎         | 129/4192 [00:28<10:10,  6.65it/s]  5%|▍         | 193/4192 [00:31<07:08,  9.34it/s]  6%|▌         | 257/4192 [00:35<05:41, 11.54it/s]  8%|▊         | 321/4192 [00:38<04:50, 13.32it/s]  9%|▉         | 385/4192 [00:42<04:19, 14.68it/s] 11%|█         | 449/4192 [00:45<03:58, 15.71it/s] 12%|█▏        | 513/4192 [00:49<03:43, 16.47it/s] 14%|█▍        | 577/4192 [00:52<03:31, 17.08it/s] 15%|█▌        | 641/4192 [00:56<03:22, 17.53it/s] 17%|█▋        | 705/4192 [00:59<03:15, 17.84it/s] 18%|█▊        | 769/4192 [01:03<03:09, 18.07it/s] 20%|█▉        | 833/4192 [01:06<03:04, 18.22it/s] 21%|██▏       | 897/4192 [01:09<02:59, 18.33it/s] 23%|██▎       | 961/4192 [01:13<02:55, 18.42it/s] 24%|██▍       | 1025/4192 [01:16<02:50, 18.58it/s] 26%|██▌       | 1089/4192 [01:20<02:46, 18.67it/s] 28%|██▊       | 1153/4192 [01:23<02:42, 18.75it/s] 29%|██▉       | 1217/4192 [01:26<02:38, 18.80it/s] 31%|███       | 1281/4192 [01:30<02:34, 18.83it/s] 32%|███▏      | 1345/4192 [01:33<02:31, 18.85it/s] 34%|███▎      | 1409/4192 [01:37<02:27, 18.88it/s] 35%|███▌      | 1473/4192 [01:40<02:23, 18.89it/s] 37%|███▋      | 1537/4192 [01:43<02:20, 18.89it/s] 38%|███▊      | 1601/4192 [01:47<02:16, 18.95it/s] 40%|███▉      | 1665/4192 [01:50<02:12, 19.00it/s] 41%|████      | 1729/4192 [01:53<02:09, 19.04it/s] 43%|████▎     | 1793/4192 [01:57<02:05, 19.06it/s] 44%|████▍     | 1857/4192 [02:00<02:02, 19.08it/s] 46%|████▌     | 1921/4192 [02:03<01:58, 19.09it/s] 47%|████▋     | 1985/4192 [02:07<01:55, 19.09it/s] 49%|████▉     | 2049/4192 [02:10<01:52, 19.09it/s] 50%|█████     | 2113/4192 [02:13<01:48, 19.08it/s] 52%|█████▏    | 2177/4192 [02:17<01:45, 19.16it/s] 53%|█████▎    | 2241/4192 [02:20<01:41, 19.20it/s] 55%|█████▍    | 2305/4192 [02:23<01:38, 19.23it/s] 57%|█████▋    | 2369/4192 [02:27<01:34, 19.26it/s] 58%|█████▊    | 2433/4192 [02:30<01:31, 19.26it/s] 60%|█████▉    | 2497/4192 [02:33<01:27, 19.29it/s] 61%|██████    | 2561/4192 [02:37<01:24, 19.32it/s] 63%|██████▎   | 2625/4192 [02:40<01:21, 19.32it/s] 64%|██████▍   | 2689/4192 [02:43<01:17, 19.32it/s] 66%|██████▌   | 2753/4192 [02:47<01:14, 19.39it/s] 67%|██████▋   | 2817/4192 [02:50<01:10, 19.46it/s] 69%|██████▊   | 2881/4192 [02:53<01:07, 19.50it/s] 70%|███████   | 2945/4192 [02:56<01:03, 19.53it/s] 72%|███████▏  | 3009/4192 [03:00<01:00, 19.56it/s] 73%|███████▎  | 3073/4192 [03:03<00:57, 19.57it/s] 75%|███████▍  | 3137/4192 [03:06<00:53, 19.59it/s] 76%|███████▋  | 3201/4192 [03:09<00:50, 19.62it/s] 78%|███████▊  | 3265/4192 [03:13<00:47, 19.72it/s] 79%|███████▉  | 3329/4192 [03:16<00:43, 19.79it/s] 81%|████████  | 3393/4192 [03:19<00:40, 19.85it/s] 82%|████████▏ | 3457/4192 [03:22<00:36, 19.87it/s] 84%|████████▍ | 3521/4192 [03:25<00:33, 19.91it/s] 86%|████████▌ | 3585/4192 [03:29<00:30, 19.92it/s] 87%|████████▋ | 3649/4192 [03:32<00:27, 19.93it/s] 89%|████████▊ | 3713/4192 [03:35<00:24, 19.95it/s] 90%|█████████ | 3777/4192 [03:38<00:20, 20.05it/s] 92%|█████████▏| 3841/4192 [03:41<00:17, 20.11it/s] 93%|█████████▎| 3905/4192 [03:44<00:14, 20.16it/s] 95%|█████████▍| 3969/4192 [03:48<00:11, 20.19it/s] 96%|█████████▌| 4033/4192 [03:51<00:07, 20.22it/s] 98%|█████████▊| 4097/4192 [03:54<00:04, 20.37it/s] 99%|█████████▉| 4161/4192 [03:56<00:01, 22.64it/s]100%|██████████| 4192/4192 [03:56<00:00, 17.73it/s]
Passed argument batch_size = auto:1. Detecting largest batch size
Determined largest batch size: 64
hf (pretrained=mistralai/Mixtral-8x22B-v0.1,parallelize=True,load_in_4bit=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)
|Tasks|Version|Filter|n-shot| Metric |Value |   |Stderr|
|-----|-------|------|-----:|--------|-----:|---|-----:|
|b4bqa|Yaml   |none  |     0|acc     |0.9866|±  |0.0035|
|     |       |none  |     0|acc_norm|0.9866|±  |0.0035|

Running evaluation for model Qwen/Qwen1.5-110B
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2024-06-13:20:51:12,528 INFO     [utils.py:148] Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-06-13:20:51:12,528 INFO     [utils.py:161] NumExpr defaulting to 8 threads.
2024-06-13:20:51:12,909 INFO     [config.py:58] PyTorch version 2.3.0 available.
2024-06-13:20:51:23,963 INFO     [__main__.py:156] Verbosity set to INFO
2024-06-13:20:51:29,939 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-06-13:20:51:54,835 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-06-13:20:51:54,837 INFO     [__main__.py:229] Selected Tasks: ['b4bqa']
2024-06-13:20:51:54,897 WARNING  [other.py:349] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home/ch225816/miniconda3/envs/harness/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 30/30 [00:00<00:00, 311.72it/s]
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:22<10:59, 22.73s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:53<12:55, 27.70s/it]Loading checkpoint shards:  10%|█         | 3/30 [01:18<11:54, 26.45s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [01:44<11:22, 26.26s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [02:10<10:54, 26.18s/it]Loading checkpoint shards:  20%|██        | 6/30 [02:36<10:22, 25.92s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [02:59<09:35, 25.02s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [03:21<08:50, 24.13s/it]Loading checkpoint shards:  30%|███       | 9/30 [03:47<08:39, 24.76s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [04:10<08:03, 24.16s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [04:36<07:46, 24.54s/it]Loading checkpoint shards:  40%|████      | 12/30 [06:38<16:18, 54.34s/it]Loading checkpoint shards:  43%|████▎     | 13/30 [07:05<13:02, 46.00s/it]Loading checkpoint shards:  47%|████▋     | 14/30 [07:30<10:33, 39.61s/it]Loading checkpoint shards:  50%|█████     | 15/30 [07:53<08:40, 34.72s/it]Loading checkpoint shards:  53%|█████▎    | 16/30 [08:19<07:29, 32.10s/it]Loading checkpoint shards:  57%|█████▋    | 17/30 [08:49<06:48, 31.40s/it]Loading checkpoint shards:  60%|██████    | 18/30 [09:13<05:51, 29.27s/it]Loading checkpoint shards:  63%|██████▎   | 19/30 [09:35<04:57, 27.07s/it]Loading checkpoint shards:  67%|██████▋   | 20/30 [10:00<04:24, 26.42s/it]Loading checkpoint shards:  70%|███████   | 21/30 [10:26<03:56, 26.29s/it]Loading checkpoint shards:  73%|███████▎  | 22/30 [10:54<03:35, 26.92s/it]Loading checkpoint shards:  77%|███████▋  | 23/30 [11:19<03:02, 26.13s/it]Loading checkpoint shards:  80%|████████  | 24/30 [11:41<02:30, 25.05s/it]Loading checkpoint shards:  83%|████████▎ | 25/30 [12:09<02:08, 25.75s/it]Loading checkpoint shards:  87%|████████▋ | 26/30 [12:33<01:41, 25.36s/it]Loading checkpoint shards:  90%|█████████ | 27/30 [14:50<02:56, 58.82s/it]Loading checkpoint shards:  93%|█████████▎| 28/30 [15:15<01:37, 48.62s/it]Loading checkpoint shards:  97%|█████████▋| 29/30 [15:40<00:41, 41.56s/it]Loading checkpoint shards: 100%|██████████| 30/30 [15:57<00:00, 34.26s/it]Loading checkpoint shards: 100%|██████████| 30/30 [15:57<00:00, 31.92s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-06-13:21:08:00,306 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:21:08:00,306 WARNING  [task.py:288] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-06-13:21:08:00,341 INFO     [task.py:343] Building contexts for task on rank 0...
2024-06-13:21:08:00,408 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/4192 [00:00<?, ?it/s]  0%|          | 1/4192 [01:07<78:31:32, 67.45s/it]  2%|▏         | 65/4192 [01:18<1:01:38,  1.12it/s]  3%|▎         | 129/4192 [01:28<31:46,  2.13it/s]   5%|▍         | 193/4192 [01:39<22:06,  3.02it/s]  6%|▌         | 257/4192 [01:49<17:19,  3.78it/s]  8%|▊         | 321/4192 [02:00<14:37,  4.41it/s]  9%|▉         | 385/4192 [02:10<12:56,  4.90it/s] 11%|█         | 449/4192 [02:20<11:49,  5.28it/s] 12%|█▏        | 513/4192 [02:30<11:03,  5.55it/s] 14%|█▍        | 577/4192 [02:41<10:28,  5.75it/s] 15%|█▌        | 641/4192 [02:51<10:01,  5.90it/s] 17%|█▋        | 705/4192 [03:01<09:40,  6.01it/s] 18%|█▊        | 769/4192 [03:11<09:23,  6.07it/s] 20%|█▉        | 833/4192 [03:22<09:08,  6.12it/s] 21%|██▏       | 897/4192 [03:32<08:55,  6.15it/s] 23%|██▎       | 961/4192 [03:42<08:41,  6.19it/s] 24%|██▍       | 1025/4192 [03:52<08:25,  6.27it/s] 26%|██▌       | 1089/4192 [04:02<08:10,  6.32it/s] 28%|██▊       | 1153/4192 [04:12<07:57,  6.36it/s] 29%|██▉       | 1217/4192 [04:22<07:45,  6.39it/s] 31%|███       | 1281/4192 [04:32<07:34,  6.41it/s] 32%|███▏      | 1345/4192 [04:42<07:23,  6.43it/s] 34%|███▎      | 1409/4192 [04:51<07:12,  6.43it/s] 35%|███▌      | 1473/4192 [05:01<07:02,  6.44it/s] 37%|███▋      | 1537/4192 [05:11<06:52,  6.44it/s] 38%|███▊      | 1601/4192 [05:21<06:41,  6.46it/s] 40%|███▉      | 1665/4192 [05:31<06:30,  6.47it/s] 41%|████      | 1729/4192 [05:41<06:20,  6.48it/s] 43%|████▎     | 1793/4192 [05:51<06:10,  6.48it/s] 44%|████▍     | 1857/4192 [06:01<06:00,  6.48it/s] 46%|████▌     | 1921/4192 [06:10<05:50,  6.48it/s] 47%|████▋     | 1985/4192 [06:20<05:40,  6.48it/s] 49%|████▉     | 2049/4192 [06:30<05:30,  6.48it/s] 50%|█████     | 2113/4192 [06:39<05:15,  6.60it/s] 52%|█████▏    | 2177/4192 [06:49<05:01,  6.68it/s] 53%|█████▎    | 2241/4192 [06:58<04:49,  6.75it/s] 55%|█████▍    | 2305/4192 [07:07<04:38,  6.79it/s] 57%|█████▋    | 2369/4192 [07:17<04:27,  6.81it/s] 58%|█████▊    | 2433/4192 [07:26<04:17,  6.84it/s] 60%|█████▉    | 2497/4192 [07:35<04:07,  6.85it/s] 61%|██████    | 2561/4192 [07:45<03:57,  6.86it/s] 63%|██████▎   | 2625/4192 [07:54<03:47,  6.88it/s] 64%|██████▍   | 2689/4192 [08:03<03:38,  6.88it/s] 66%|██████▌   | 2753/4192 [08:12<03:29,  6.88it/s] 67%|██████▋   | 2817/4192 [08:22<03:19,  6.89it/s] 69%|██████▊   | 2881/4192 [08:31<03:10,  6.90it/s] 70%|███████   | 2945/4192 [08:40<03:00,  6.91it/s] 72%|███████▏  | 3009/4192 [08:49<02:51,  6.92it/s] 73%|███████▎  | 3073/4192 [08:59<02:41,  6.93it/s] 75%|███████▍  | 3137/4192 [09:08<02:32,  6.93it/s] 76%|███████▋  | 3201/4192 [09:17<02:22,  6.93it/s] 78%|███████▊  | 3265/4192 [09:26<02:13,  6.94it/s] 79%|███████▉  | 3329/4192 [09:35<02:04,  6.94it/s] 81%|████████  | 3393/4192 [09:45<01:55,  6.94it/s] 82%|████████▏ | 3457/4192 [09:54<01:45,  6.94it/s] 84%|████████▍ | 3521/4192 [10:03<01:35,  7.01it/s] 86%|████████▌ | 3585/4192 [10:12<01:26,  7.05it/s] 87%|████████▋ | 3649/4192 [10:21<01:16,  7.08it/s] 89%|████████▊ | 3713/4192 [10:30<01:07,  7.11it/s] 90%|█████████ | 3777/4192 [10:39<00:58,  7.12it/s] 92%|█████████▏| 3841/4192 [10:48<00:49,  7.12it/s] 93%|█████████▎| 3905/4192 [10:57<00:40,  7.13it/s] 95%|█████████▍| 3969/4192 [11:05<00:31,  7.15it/s] 96%|█████████▌| 4033/4192 [11:14<00:22,  7.17it/s] 98%|█████████▊| 4097/4192 [11:23<00:13,  7.18it/s] 99%|█████████▉| 4161/4192 [11:28<00:03,  8.43it/s]100%|██████████| 4192/4192 [11:28<00:00,  6.09it/s]
Passed argument batch_size = auto:1. Detecting largest batch size
Determined largest batch size: 64
hf (pretrained=Qwen/Qwen1.5-110B,parallelize=True,load_in_4bit=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)
|Tasks|Version|Filter|n-shot| Metric |Value |   |Stderr|
|-----|-------|------|-----:|--------|-----:|---|-----:|
|b4bqa|Yaml   |none  |     0|acc     |0.9933|±  |0.0025|
|     |       |none  |     0|acc_norm|0.9933|±  |0.0025|

All evaluations completed.
